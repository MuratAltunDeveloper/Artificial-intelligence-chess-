{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10086949,"sourceType":"datasetVersion","datasetId":6219321},{"sourceId":10097989,"sourceType":"datasetVersion","datasetId":6227771},{"sourceId":10128734,"sourceType":"datasetVersion","datasetId":6250731},{"sourceId":10128827,"sourceType":"datasetVersion","datasetId":6250794},{"sourceId":10163383,"sourceType":"datasetVersion","datasetId":6276093},{"sourceId":10184169,"sourceType":"datasetVersion","datasetId":6291361}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":null,"end_time":null,"environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-12-11T07:56:46.454954","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"116f4776","cell_type":"code","source":"#ULTRA SUPER SIGMA CHESS AI","metadata":{"execution":{"iopub.status.busy":"2024-12-13T17:51:26.838634Z","iopub.execute_input":"2024-12-13T17:51:26.839036Z","iopub.status.idle":"2024-12-13T17:51:26.862873Z","shell.execute_reply.started":"2024-12-13T17:51:26.838999Z","shell.execute_reply":"2024-12-13T17:51:26.861898Z"},"id":"t4jK41UULfwI","papermill":{"duration":0.011291,"end_time":"2024-12-11T07:56:48.737620","exception":false,"start_time":"2024-12-11T07:56:48.726329","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":1},{"id":"c3579ed1","cell_type":"code","source":"!pip install chess","metadata":{"execution":{"iopub.status.busy":"2024-12-13T17:51:26.864578Z","iopub.execute_input":"2024-12-13T17:51:26.864956Z","iopub.status.idle":"2024-12-13T17:51:40.122724Z","shell.execute_reply.started":"2024-12-13T17:51:26.864899Z","shell.execute_reply":"2024-12-13T17:51:40.121513Z"},"id":"gfMjit5oLfwI","outputId":"d0fef2ed-63fe-48c8-9acb-c54b09a6799f","papermill":{"duration":11.799166,"end_time":"2024-12-11T07:57:00.540221","exception":false,"start_time":"2024-12-11T07:56:48.741055","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Collecting chess\n  Downloading chess-1.11.1.tar.gz (156 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: chess\n  Building wheel for chess (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for chess: filename=chess-1.11.1-py3-none-any.whl size=148498 sha256=458ebbed29545b453cef5ad9a663c506983dd2d813a2751fd63b4a62833c3093\n  Stored in directory: /root/.cache/pip/wheels/2e/2d/23/1bfc95db984ed3ecbf6764167dc7526d0ab521cf9a9852544e\nSuccessfully built chess\nInstalling collected packages: chess\nSuccessfully installed chess-1.11.1\n","output_type":"stream"},{"name":"stdout","output_type":"stream","text":["  Building wheel for chess (setup.py) ... \u001b[?25l-"]},{"name":"stdout","output_type":"stream","text":["\b \b\\"]},{"name":"stdout","output_type":"stream","text":["\b \bdone\r\n","\u001b[?25h  Created wheel for chess: filename=chess-1.11.1-py3-none-any.whl size=148498 sha256=bc31c4504ce0a61c83dba982c838348c14522be72dac83344093cf34f1e9c975\r\n","  Stored in directory: /root/.cache/pip/wheels/2e/2d/23/1bfc95db984ed3ecbf6764167dc7526d0ab521cf9a9852544e\r\n","Successfully built chess\r\n"]},{"name":"stdout","output_type":"stream","text":["Installing collected packages: chess\r\n"]},{"name":"stdout","output_type":"stream","text":["Successfully installed chess-1.11.1\r\n"]}],"execution_count":2},{"id":"ba59618d","cell_type":"code","source":"!cp /kaggle/input/stockfish-model/stockfish/stockfish-ubuntu-x86-64-avx2 /kaggle/working/\n!chmod +x /kaggle/working/stockfish-ubuntu-x86-64-avx2","metadata":{"execution":{"iopub.status.busy":"2024-12-13T17:51:40.124193Z","iopub.execute_input":"2024-12-13T17:51:40.124540Z","iopub.status.idle":"2024-12-13T17:51:43.079805Z","shell.execute_reply.started":"2024-12-13T17:51:40.124508Z","shell.execute_reply":"2024-12-13T17:51:43.078262Z"},"id":"RYnWlePILfwJ","outputId":"fe7701d7-6c3b-490f-9040-27a1a91f5c32","papermill":{"duration":3.024651,"end_time":"2024-12-11T07:57:03.568742","exception":false,"start_time":"2024-12-11T07:57:00.544091","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":3},{"id":"fbfd357d","cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport math\n\nimport chess\n\nfrom collections import deque\n\nimport tensorflow as tf\n\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.initializers import HeNormal\n\nimport chess.engine\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\nimport threading\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nclass GameState:\n    row = 8\n    col = 8\n    promotion_indexes = {\n        chess.KNIGHT: 0,\n        chess.ROOK: 1,\n        chess.BISHOP: 2\n    }\n\n    def __init__(self) -> None:\n        self.board = chess.Board()\n        self.repetition_count = 0\n        self.player_color: chess.Color = chess.WHITE\n\n    def get_initial_state(self):\n        self.board.reset()\n\n        return self.get_current_state()\n\n    def get_current_state(self, T=8):\n        input_tensor = np.zeros((8, 8, 119), dtype=np.uint8)\n\n        for t in range(T):\n            _t = T - t - 1\n            if len(self.board.move_stack) < _t:\n                continue\n\n            self.create_input(input_tensor, _t)\n\n        color = 0 if self.board.turn == chess.WHITE else 1\n        input_tensor[:, :, 112] = color\n\n        input_tensor[:, :, 113] = len(self.board.move_stack) > 0\n\n        p1_castling = (1 * self.board.has_kingside_castling_rights(chess.WHITE)) | (2 * self.board.has_queenside_castling_rights(chess.WHITE))\n        p1_castling_bit = format(p1_castling, \"02b\")\n        input_tensor[:, :, 114] = int(p1_castling_bit[0])\n        input_tensor[:, :, 115] = int(p1_castling_bit[1])\n\n        p2_castling = (1 * self.board.has_kingside_castling_rights(chess.BLACK)) | (2 * self.board.has_queenside_castling_rights(chess.BLACK))\n        p2_castling_bit = format(p2_castling, \"02b\")\n        input_tensor[:, :, 116] = int(p2_castling_bit[0])\n        input_tensor[:, :, 117] = int(p2_castling_bit[1])\n\n        input_tensor[:, :, 118] = int(self.board.is_fifty_moves())\n\n        return np.expand_dims(input_tensor, axis=0)\n\n    def get_next_state(self, action: int):\n        source_index = action // 73\n        destination_index = 0\n        move_type = action % 73\n\n        promotion = None\n\n        if move_type < 56:\n            direction = move_type // 7\n            movement = (move_type % 7) + 1\n\n            destination_index = source_index + (movement * 8) if direction == 0 else destination_index\n            destination_index = source_index + (movement * 9) if direction == 1 else destination_index\n            destination_index = source_index + movement if direction == 2 else destination_index\n            destination_index = source_index + (movement * -7) if direction == 3 else destination_index\n            destination_index = source_index + (movement * -8) if direction == 4 else destination_index\n            destination_index = source_index + (movement * -9) if direction == 5 else destination_index\n            destination_index = source_index + (-movement) if direction == 6 else destination_index\n            destination_index = source_index + (movement * 7) if direction == 7 else destination_index\n        elif move_type >= 56 and move_type < 64:\n            direction = move_type - 56\n\n            destination_index = source_index + 17 if direction == 0 else destination_index\n            destination_index = source_index + 10 if direction == 1 else destination_index\n            destination_index = source_index - 6 if direction == 2 else destination_index\n            destination_index = source_index - 15 if direction == 3 else destination_index\n            destination_index = source_index - 17 if direction == 4 else destination_index\n            destination_index = source_index - 10 if direction == 5 else destination_index\n            destination_index = source_index + 6 if direction == 6 else destination_index\n            destination_index = source_index + 15 if direction == 7 else destination_index\n        else:\n            direction = (move_type - 64) // 3\n            promotion_index = (move_type - 64) % 3\n\n            promotion = chess.KNIGHT if promotion_index == 0 else (chess.ROOK if promotion_index == 1 else chess.BISHOP)\n\n            color_value = 1 if self.board.turn == chess.WHITE else -1\n\n            if direction == 0:\n                destination_index = source_index + (8 * color_value)\n            elif direction == 1:\n                destination_index = source_index + (9 * color_value)\n            else:\n                destination_index = source_index + (7 * color_value)\n\n        from_square = chess.Square(source_index)\n        to_square = chess.Square(destination_index)\n\n        promotion_rank = 7 if self.board.turn == chess.WHITE else 0\n\n        if promotion is None:\n            if self.board.piece_type_at(from_square) == chess.PAWN and chess.square_rank(to_square) == promotion_rank:\n                promotion = chess.QUEEN\n\n        move = chess.Move(from_square, to_square, promotion)\n\n        self.apply_action(move)\n\n        return move, self.get_current_state()\n\n    def apply_action(self, move: chess.Move):\n        try:\n            self.board.push(move)\n        except Exception as e:\n            print(list(self.board.legal_moves))\n            print(self.get_valid_moves())\n\n            print(e)\n\n            raise Exception(\"Error\")\n\n    def create_input(self, input_tensor: np.ndarray, t: int):\n        piece_types = {\n            chess.PAWN: 0,\n            chess.KNIGHT: 1,\n            chess.BISHOP: 2,\n            chess.ROOK: 3,\n            chess.QUEEN: 4,\n            chess.KING: 5\n        }\n\n        board = self.board.copy()\n        for _ in range(t):\n            board.pop()\n\n        transposition_key = board._transposition_key()\n\n        for square in chess.SQUARES:\n            piece = board.piece_at(square)\n\n            if piece is None:\n                continue\n\n            piece_index = piece_types[piece.piece_type]\n            piece_color = 0 if piece.color == chess.WHITE else 1\n\n            index = (t * 14) + (piece_color * 6) + piece_index\n            input_tensor[square // 8][square % 8][index] = 1\n\n        repetition_count = 0\n        index = (t * 14) + 12\n\n        try:\n            while board.move_stack:\n                move = board.pop()\n                if board.is_irreversible(move):\n                    break\n\n                if board._transposition_key() == transposition_key:\n                    repetition_count += 1\n\n                if repetition_count == 3:\n                    break\n        finally:\n            repetition_count = 3 if repetition_count > 3 else repetition_count\n\n            repetition_count_bits = [int(x) for x in format(repetition_count, \"02b\")]\n            input_tensor[:, :, index] = repetition_count_bits[0]\n            input_tensor[:, :, index + 1] = repetition_count_bits[1]\n\n    def get_valid_moves(self):\n        legal_moves = []\n\n        for valid_move in self.board.legal_moves:\n            s_row, s_col, from_square_index = self.index_of_square(valid_move.from_square)\n            d_row, d_col, to_square_index = self.index_of_square(valid_move.to_square)\n\n            if valid_move.promotion:\n                direction = self.direction_of_move_for_ray_directions(s_row, s_col, d_row, d_col)\n\n                if valid_move.promotion == chess.QUEEN:\n                    index = (from_square_index * 73) + (direction * 7)\n                    legal_moves.append(index)\n                else:\n                    promotion_index = self.promotion_indexes[valid_move.promotion]\n\n                    if direction > 2 and direction < 6:\n                        direction = 0 if direction == 4 else (1 if direction == 5 else 2)\n                    elif direction == 7:\n                        direction = 2\n\n                    index = (from_square_index * 73) + ((direction * 3) + promotion_index + 64)\n                    legal_moves.append(index)\n            elif self.board.piece_type_at(valid_move.from_square) == chess.KNIGHT:\n                direction = self.direction_of_move_for_knights(s_row, s_col, d_row, d_col)\n\n                index = (from_square_index * 73) + direction + 56\n                legal_moves.append(index)\n\n            else:\n                direction = self.direction_of_move_for_ray_directions(s_row, s_col, d_row, d_col)\n                count_of_square = self.count_of_square_for_movement(s_row, s_col, d_row, d_col) - 1\n\n                index = (from_square_index * 73) + ((direction * 7) + count_of_square)\n                legal_moves.append(index)\n\n        return legal_moves\n\n    def index_of_square(self, square: chess.Square):\n        row = chess.square_rank(square)\n        col = chess.square_file(square)\n        index = (row * 8) + col\n\n        return row, col, index\n\n    def direction_of_move_for_ray_directions(self, s_row: int, s_col: int, d_row: int, d_col: int):\n        delta_x = d_col - s_col\n        delta_y = d_row - s_row\n\n        if delta_x == 0:\n            return 0 if delta_y > 0 else 4\n\n        if delta_y == 0:\n            return 2 if delta_x > 0 else 6\n\n        if delta_x < 0:\n            return 7 if delta_y > 0 else 5\n\n        return 1 if delta_y > 0 else 3\n\n    def direction_of_move_for_knights(self, s_row: int, s_col: int, d_row: int, d_col: int):\n        delta_x = d_col - s_col\n        delta_y = d_row - s_row\n\n        if delta_x == 1:\n            return 0 if delta_y > 0 else 3\n\n        if delta_x == 2:\n            return 1 if delta_y > 0 else 2\n\n        if delta_x == -1:\n            return 7 if delta_y > 0 else 4\n\n        return 6 if delta_y > 0 else 5\n\n    def count_of_square_for_movement(self, s_row: int, s_col: int, d_row: int, d_col: int):\n        delta_x = d_col - s_col\n        delta_y = d_row - s_row\n\n        return max(abs(delta_x), abs(delta_y))\n\n    def get_winner(self):\n        result = self.board.result()\n\n        if result == \"1-0\":\n            return chess.WHITE\n\n        if result == \"0-1\":\n            return chess.BLACK\n\n        return 2\n\n    def is_terminal(self):\n        return self.board.is_game_over()\n\n    def clone(self):\n        cloned_state = GameState()\n        cloned_state.board = self.board.copy()\n\n        return cloned_state\n\nclass Node:\n    def __init__(self, state, parent=None, prior_prob=1.0):\n        self.state = state\n        self.parent = parent\n        self.children = {}\n        self.visits = 0\n        self.value_sum = 0\n        self.prior_prob = prior_prob\n        self.is_expanded = False\n\n    @property\n    def value(self):\n        return self.value_sum / (self.visits + 1e-5)\n\n    def expand(self, action_probs):\n        if not self.children:\n            for action, prob in enumerate(action_probs):\n                if prob > 0 and action not in self.children:\n                    next_state = self.state.clone()\n                    next_state.get_next_state(action)\n                    self.children[action] = Node(next_state, parent=self, prior_prob=prob)\n\n            self.is_expanded = len(self.children) > 0\n\n    def select(self, c_puct=1.0):\n      if not self.children:  # If no children exist\n          return None, None\n\n      max_ucb = -float('inf')\n      best_action = None\n      best_child = None\n\n      for action, child in self.children.items():\n          ucb = child.value + c_puct * child.prior_prob * (math.sqrt(self.visits) / (1 + child.visits))\n          if ucb > max_ucb:\n              max_ucb = ucb\n              best_action = action\n              best_child = child\n\n      return best_action, best_child\n\n    def backup(self, value):\n        self.visits += 1\n        self.value_sum += value\n        if self.parent:\n            self.parent.backup(-value)\n\nclass MCTS:\n    def __init__(self, model, c_puct=1.0, simulations=300):\n        self.model = model\n        self.c_puct = c_puct\n        self.simulations = simulations\n\n    def add_dirichlet_noise(self, node, valid_moves):\n        noise = np.random.dirichlet([0.3] * len(valid_moves))\n        for idx, action in enumerate(valid_moves):\n            if action in node.children:\n                node.children[action].prior_prob = \\\n                    0.75 * node.children[action].prior_prob + 0.25 * noise[idx]\n\n    def run(self, initial_state, temperature=1.0):\n        root = Node(initial_state)\n\n        action_probs, value = self.evaluate(initial_state)\n        valid_moves = initial_state.get_valid_moves()\n\n        noise = np.random.dirichlet([0.3] * len(valid_moves))\n\n        for idx, action in enumerate(valid_moves):\n            prob = action_probs[action]\n            noisy_prob = 0.75 * prob + 0.25 * noise[idx]\n            next_state = initial_state.clone()\n            next_state.get_next_state(action)\n            root.children[action] = Node(next_state, parent=root, prior_prob=noisy_prob)\n\n        for _ in range(self.simulations):\n            node = root\n\n            while node.children and not node.state.is_terminal():\n                action, child_node = node.select(self.c_puct)\n\n                if child_node is None:\n                    break\n\n                node = child_node\n\n            if not node.state.is_terminal():\n                action_probs, value = self.evaluate(node.state)\n                valid_moves = node.state.get_valid_moves()\n                node.expand(action_probs)\n            else:\n                value = node.state.get_winner()\n                value = 1 if value == node.state.player_color else (0 if value == 2 else -1)\n\n            node.backup(value)\n\n        return self.get_action_probs(root, temperature)\n\n    def evaluate(self, state):\n        state_tensor = state.get_current_state()\n        # state_tensor = np.expand_dims(state_tensor, axis=0)\n\n        policy, value = self.model.predict(state_tensor, verbose=0)\n\n        # Mask invalid moves\n        valid_moves = state.get_valid_moves()\n        mask = np.zeros(policy.shape[1])\n        mask[valid_moves] = 1\n\n        policy = policy[0] * mask\n\n        # Normalize\n        sum_policy = np.sum(policy)\n        if sum_policy > 0:\n            policy /= sum_policy\n        else:\n            # If all moves were masked, use uniform distribution over valid moves\n            policy = mask / np.sum(mask)\n\n        return policy, value[0][0]\n\n    def get_action_probs(self, root, temperature=1.0):\n        visits = np.array([child.visits for action, child in root.children.items()])\n        actions = list(root.children.keys())\n\n        if temperature == 0:  # Pure exploitation\n            action_idx = np.argmax(visits)\n            probs = np.zeros_like(visits)\n            probs[action_idx] = 1\n        else:\n            # Apply temperature\n            visits = visits ** (1 / temperature)\n            probs = visits / np.sum(visits)\n\n        # Convert to full move probability vector\n        full_probs = np.zeros(4672)  # Adjust size based on your action space\n        for action, prob in zip(actions, probs):\n            full_probs[action] = prob\n\n        return full_probs\n\nclass ReplayBuffer:\n    def __init__(self, maxlen=500000):\n        self.buffer = deque(maxlen=maxlen)\n        self.current_size = 0\n        self.lock = threading.Lock()\n\n    def store(self, state, policy, value):\n        \"\"\"Store a single game state transition\"\"\"\n        self.buffer.append({\n            'state': state,\n            'policy': policy,\n            'value': value\n        })\n        self.current_size = len(self.buffer)\n\n    def store_multiple_data(self, states, policies, value):\n        with self.lock:\n            for s, p, v in zip(states, policies, [value]):\n                self.store(s, p, v)\n\n    def sample(self, batch_size):\n        \"\"\"Sample a batch with augmentations\"\"\"\n        if self.current_size < batch_size:\n            batch_size = self.current_size\n\n        indices = np.random.choice(self.current_size, batch_size)\n        states, policies, values = [], [], []\n\n        for idx in indices:\n            sample = self.buffer[idx]\n            # Get augmented samples\n            aug_states, aug_policies = self._augment_sample(\n                sample['state'],\n                sample['policy']\n            )\n\n            # Add all augmentations\n            states.extend(aug_states)\n            policies.extend(aug_policies)\n            values.extend([sample['value']] * len(aug_states))\n\n        return np.array(states), np.array(policies), np.array(values)\n\n    def _augment_sample(self, state, policy):\n        \"\"\"Generate valid augmentations for a single sample\"\"\"\n        # Remove batch dimension if present\n        if len(state.shape) == 4:\n            state = np.squeeze(state, axis=0)\n\n        augmented_states = [state]\n        augmented_policies = [policy]\n\n        # Horizontal flip\n        flip_h = np.flip(state, axis=1)\n        augmented_states.append(flip_h)\n        augmented_policies.append(policy)  # Policy needs game-specific mapping\n\n        # Vertical flip\n        flip_v = np.flip(state, axis=0)\n        augmented_states.append(flip_v)\n        augmented_policies.append(policy)  # Policy needs game-specific mapping\n\n        # Diagonal flip (only if shape allows)\n        if state.shape[0] == state.shape[1]:\n            diag = np.transpose(state, (1, 0, 2))\n            augmented_states.append(diag)\n            augmented_policies.append(policy)  # Policy needs game-specific mapping\n\n        return augmented_states, augmented_policies\n\n    def __len__(self):\n        return self.current_size\n\n# tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n\n# tf.tpu.experimental.initialize_tpu_system(tpu)\n# tpu_strategy = tf.distribute.TPUStrategy(tpu)\n\nprint(\"All devices: \", tf.config.list_logical_devices('GPU'))\n\npolicy = tf.keras.mixed_precision.Policy('mixed_float16')\ntf.keras.mixed_precision.set_global_policy(policy)","metadata":{"execution":{"iopub.status.busy":"2024-12-13T17:51:43.083824Z","iopub.execute_input":"2024-12-13T17:51:43.084258Z","iopub.status.idle":"2024-12-13T17:51:56.365538Z","shell.execute_reply.started":"2024-12-13T17:51:43.084210Z","shell.execute_reply":"2024-12-13T17:51:56.363346Z"},"id":"rBlKKoQmLfwJ","outputId":"026c181e-e036-496a-f599-79c3e2527810","papermill":{"duration":12.303461,"end_time":"2024-12-11T07:57:15.876062","exception":false,"start_time":"2024-12-11T07:57:03.572601","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"All devices:  [LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n","output_type":"stream"}],"execution_count":4},{"id":"32d4ea8c","cell_type":"code","source":"","metadata":{"id":"yEEbn7CxLfwL","papermill":{"duration":0.003708,"end_time":"2024-12-11T07:57:15.883543","exception":false,"start_time":"2024-12-11T07:57:15.879835","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"6f6d9560","cell_type":"code","source":"","metadata":{"papermill":{"duration":0.004401,"end_time":"2024-12-11T07:57:15.891478","exception":false,"start_time":"2024-12-11T07:57:15.887077","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"3c2ad56b","cell_type":"code","source":"\n'''\nimport numpy as np\nimport threading\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\n\ndef EfficientNet_block(inputs, filters=256, expansion_factor=6, stride=1, se_ratio=0.25):\n    \"\"\"\n    EfficientNet tarzı bir MBConv bloğu.\n\n    Args:\n        inputs: Giriş tensörü.\n        filters: Çıkış filtrelerinin sayısı.\n        expansion_factor: Genişletme oranı (Bottleneck genişletme için).\n        stride: Adım boyutu (ör. 1 veya 2).\n        se_ratio: Squeeze-and-Excitation (SE) oranı.\n\n    Returns:\n        EfficientNet MBConv bloğunun çıktısı.\n    \"\"\"\n    input_channels = inputs.shape[-1]  # Giriş kanal sayısı\n\n    # 1. Expand (Genişletme)\n    x = layers.Conv2D(input_channels * expansion_factor, (1, 1), strides=1, padding=\"same\",\n                      kernel_initializer=\"he_normal\", use_bias=False)(inputs)\n    x = layers.BatchNormalization()(x)\n    x = layers.ReLU()(x)\n\n    # 2. Depthwise Convolution (Derinlikçe Ayrık Evrişim)\n    x = layers.DepthwiseConv2D((3, 3), strides=stride, padding=\"same\",\n                               depthwise_initializer=\"he_normal\", use_bias=False)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.ReLU()(x)\n\n    # 3. Squeeze-and-Excitation (SE Blok)\n    if se_ratio:\n        se = layers.GlobalAveragePooling2D()(x)\n        se = layers.Reshape((1, 1, x.shape[-1]))(se)\n        se = layers.Conv2D(int(input_channels * se_ratio), (1, 1), activation=\"relu\", kernel_initializer=\"he_normal\")(se)\n        se = layers.Conv2D(x.shape[-1], (1, 1), activation=\"sigmoid\", kernel_initializer=\"he_normal\")(se)\n        x = layers.Multiply()([x, se])\n\n    # 4. Project (Daraltma)\n    x = layers.Conv2D(filters, (1, 1), strides=1, padding=\"same\",\n                      kernel_initializer=\"he_normal\", use_bias=False)(x)\n    x = layers.BatchNormalization()(x)\n\n    # 5. Shortcut Connection (Skip Connection)\n    if stride == 1 and inputs.shape[-1] == filters:\n        x = layers.Add()([inputs, x])\n\n    return x\n\n\n\ndef sigmachess_network(input_shape=(8, 8, 119)):\n    inputs = layers.Input(shape=input_shape)\n\n    x = layers.Conv2D(256, (3, 3), strides=1, padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False)(inputs)\n    x = layers.BatchNormalization()(x)\n    x = layers.ReLU()(x)\n\n    for _ in range(19):\n        x = EfficientNet_block(x)\n\n    policy = layers.Conv2D(256, (3, 3), strides=1, padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False)(x)\n    policy = layers.BatchNormalization()(policy)\n    policy = layers.ReLU()(policy)\n    policy = layers.Conv2D(73, (1, 1), strides=1, padding=\"same\", kernel_initializer=\"he_normal\")(policy)\n    policy = layers.Flatten()(policy)\n    policy = layers.Softmax(name=\"policy_output\")(policy)\n\n    value = layers.Conv2D(1, (1, 1), strides=1, padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False)(x)\n    value = layers.BatchNormalization()(value)\n    value = layers.ReLU()(value)\n    value = layers.Flatten()(value)\n    value = layers.Dense(256, activation=\"relu\", kernel_initializer=\"he_normal\")(value)\n    value = layers.Dense(1, activation=\"tanh\", name=\"value_output\", kernel_initializer=\"he_normal\")(value)\n\n    model = models.Model(inputs=inputs, outputs=[policy, value])\n\n    return model\n\ndef create_model():\n    model = sigmachess_network()\n\n    model.compile(\n        optimizer=Adam(learning_rate=0.00001),\n        loss={\n            \"policy_output\": \"categorical_crossentropy\",\n            \"value_output\": \"mean_squared_error\"\n        },\n        metrics={\n            \"policy_output\": \"accuracy\",\n            \"value_output\": \"mse\"\n        }\n    )\n\n    return model\n\ndef play_vs_stockfish(model, game, replay_buffer):\n    state = GameState()\n    temperature = 1.0 if game < 5 else 0.1\n\n    w_states, w_policies, w_rewards = [], [], []\n    player = np.random.choice([chess.WHITE, chess.BLACK])\n\n    engine = chess.engine.SimpleEngine.popen_uci(r\"/kaggle/working/stockfish-ubuntu-x86-64-avx2\")\n\n    while not state.is_terminal():\n        if state.board.turn == player:\n            mcts = MCTS(model, 1.0, 10)\n            action_probs = mcts.run(state, temperature)\n\n            w_states.append(state.get_current_state())\n            w_policies.append(action_probs)\n\n            action = np.random.choice(len(action_probs), p=action_probs)\n            state.get_next_state(action)\n        else:\n            result = engine.play(state.board, chess.engine.Limit(0.04))\n            state.apply_action(result.move)\n\n    engine.close()\n\n    winner = state.get_winner()\n    w_value = 1 if winner == player else (0 if winner == 2 else -1)\n\n    print(player, state.board.board_fen())\n\n    replay_buffer.store_multiple_data(w_states, w_policies, w_value)\n\ndef self_play(model, num_games=100, max_workers=5):\n    replay_buffer = ReplayBuffer(maxlen=500000)\n\n    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n        futures = [\n            executor.submit(play_vs_stockfish, model, i, replay_buffer)\n            for i in range(num_games)\n        ]\n\n        for future in as_completed(futures):\n            future.result()\n\n    print(\"Self-play completed\")\n\n    return replay_buffer\n\ndef prepare_validation_data(replay_buffer=None, filename=\"validation_data.npy\"):\n    try:\n        # First, try to load existing validation data\n        data = np.load(filename, allow_pickle=True).item()\n        print(f\"Loaded existing validation data from {filename}\")\n        return data['x_val'], {\n            \"policy_output\": data['y_val_policy'],\n            \"value_output\": data['y_val_value']\n        }\n    except (FileNotFoundError, IOError):\n        # If no existing data, create new validation dataset\n        if replay_buffer is None:\n            # If no replay buffer provided, generate synthetic data\n            x_val = np.random.random((100, 8, 8, 119))\n            y_val_policy = np.random.randint(0, 73, size=(100, 1))\n            y_val_value = np.random.random((100, 1)) * 2 - 1  # Values between -1 and 1\n        else:\n            # Use replay buffer to generate validation data\n            states, policies, rewards = replay_buffer.sample(100)\n            x_val = np.squeeze(states)\n            y_val_policy = policies\n            y_val_value = np.array(rewards).reshape(-1, 1)\n\n        # One-hot encode policy output\n        y_val_policy_onehot = np.eye(73)[y_val_policy.flatten()]\n\n        # Prepare data dictionary\n        validation_data = {\n            \"x_val\": x_val,\n            \"y_val_policy\": y_val_policy_onehot,\n            \"y_val_value\": y_val_value\n        }\n\n        # Save the validation data\n        np.save(filename, validation_data)\n        print(f\"Created and saved new validation data to {filename}\")\n\n        return x_val, {\n            \"policy_output\": y_val_policy_onehot,\n            \"value_output\": y_val_value\n        }\n\ndef create_callbacks(checkpoint_path=\"kaggle/working/sigma_checkpoint.weights.h5\"):\n    checkpoint = ModelCheckpoint(\n        filepath=checkpoint_path,\n        save_weights_only=True,\n        monitor=\"loss\",\n        mode=\"min\",\n        save_best_only=True,\n        save_freq=\"epoch\",\n        verbose=1\n    )\n    return [checkpoint]\n\ndef train_model(model, replay_buffer: ReplayBuffer, batch_size=256, epochs=3, checkpoint_path=\"kaggle/working/sigma_checkpoint.weights.h5\"):\n    x_val, y_val = prepare_validation_data()\n\n    callbacks = create_callbacks(checkpoint_path)\n\n    total_policy_loss = 0\n    total_value_loss = 0\n    epoch_count = 0\n\n    for epoch in range(epochs):\n        states, policies, values = replay_buffer.sample(batch_size)\n\n        states = np.squeeze(states)\n        if len(states.shape) == 3:\n            states = np.expand_dims(states, -1)\n\n        values = np.array(values).reshape(-1, 1)\n\n        history = model.fit(\n            states,\n            { \"policy_output\": policies, \"value_output\": values },\n            batch_size=batch_size,\n            epochs=1,\n            callbacks=callbacks,\n            verbose=1\n        )\n\n        total_policy_loss += history.history['policy_output_loss'][0]\n        total_value_loss += history.history['value_output_loss'][0]\n        epoch_count += 1\n\n    avg_policy_loss = total_policy_loss / epoch_count\n    avg_value_loss = total_value_loss / epoch_count\n\n    print(f\"\\nAverage Policy Output Loss: {avg_policy_loss}\")\n    print(f\"Average Value Output Loss: {avg_value_loss}\")\n\n    return avg_policy_loss, avg_value_loss\n\nis_stop = False\n\ndef train_sigmachess(model, num_iterations=100, num_games_per_iteration=100):\n    global is_stop\n\n    # Değişkenleri başlatın\n    total_policy_loss = 0\n    total_value_loss = 0\n    iteration_count = 0\n\n    for iteration in range(num_iterations):\n        print(f\"Iteration {iteration + 1}/{num_iterations}\")\n\n        replay_buffer = self_play(model, num_games_per_iteration)\n        policy_loss, value_loss = train_model(model, replay_buffer)\n\n        # Kayıpları biriktir\n        total_policy_loss += policy_loss\n        total_value_loss += value_loss\n        iteration_count += 1\n\n        # Her 5 iteration'da bir ortalamaları yazdır\n        if iteration_count % 5 == 0:\n            avg_policy_loss = total_policy_loss / iteration_count\n            avg_value_loss = total_value_loss / iteration_count\n            print(f\"\\n[After {iteration_count} Iterations]\")\n            print(f\"Average Policy Output Loss: {avg_policy_loss}\")\n            print(f\"Average Value Output Loss: {avg_value_loss}\")\n\n        if is_stop:\n            break\n\n    model.save(\"kaggle/working/full_model.keras\")\n\n\ndef stop():\n    global is_stop\n\n    while True:\n        inp = input(\"\")\n        if inp == \"stop\":\n            is_stop = True\n            print(\"After the iteration is completed, the training will be stopped and the model will be saved!\")\n\n            break\n\nt = threading.Thread(target=stop, daemon=True)\nt.start()\n\nmodel = create_model()\ntrain_sigmachess(model, num_iterations=7000, num_games_per_iteration=15)\n\n'''\n","metadata":{"execution":{"iopub.status.busy":"2024-12-13T17:51:56.368361Z","iopub.execute_input":"2024-12-13T17:51:56.369279Z","iopub.status.idle":"2024-12-13T17:51:56.410776Z","shell.execute_reply.started":"2024-12-13T17:51:56.369211Z","shell.execute_reply":"2024-12-13T17:51:56.409531Z"},"id":"vsoo7SmaO1tk","outputId":"a3a069d6-e38f-4c22-e219-11e7fcc95766","papermill":{"duration":0.019277,"end_time":"2024-12-11T07:57:15.914260","exception":false,"start_time":"2024-12-11T07:57:15.894983","status":"completed"},"tags":[],"trusted":true},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'\\nimport numpy as np\\nimport threading\\nfrom tensorflow.keras import layers, models\\nfrom tensorflow.keras.optimizers import Adam\\nfrom tensorflow.keras.callbacks import ModelCheckpoint\\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\\n\\n\\ndef EfficientNet_block(inputs, filters=256, expansion_factor=6, stride=1, se_ratio=0.25):\\n    \"\"\"\\n    EfficientNet tarzı bir MBConv bloğu.\\n\\n    Args:\\n        inputs: Giriş tensörü.\\n        filters: Çıkış filtrelerinin sayısı.\\n        expansion_factor: Genişletme oranı (Bottleneck genişletme için).\\n        stride: Adım boyutu (ör. 1 veya 2).\\n        se_ratio: Squeeze-and-Excitation (SE) oranı.\\n\\n    Returns:\\n        EfficientNet MBConv bloğunun çıktısı.\\n    \"\"\"\\n    input_channels = inputs.shape[-1]  # Giriş kanal sayısı\\n\\n    # 1. Expand (Genişletme)\\n    x = layers.Conv2D(input_channels * expansion_factor, (1, 1), strides=1, padding=\"same\",\\n                      kernel_initializer=\"he_normal\", use_bias=False)(inputs)\\n    x = layers.BatchNormalization()(x)\\n    x = layers.ReLU()(x)\\n\\n    # 2. Depthwise Convolution (Derinlikçe Ayrık Evrişim)\\n    x = layers.DepthwiseConv2D((3, 3), strides=stride, padding=\"same\",\\n                               depthwise_initializer=\"he_normal\", use_bias=False)(x)\\n    x = layers.BatchNormalization()(x)\\n    x = layers.ReLU()(x)\\n\\n    # 3. Squeeze-and-Excitation (SE Blok)\\n    if se_ratio:\\n        se = layers.GlobalAveragePooling2D()(x)\\n        se = layers.Reshape((1, 1, x.shape[-1]))(se)\\n        se = layers.Conv2D(int(input_channels * se_ratio), (1, 1), activation=\"relu\", kernel_initializer=\"he_normal\")(se)\\n        se = layers.Conv2D(x.shape[-1], (1, 1), activation=\"sigmoid\", kernel_initializer=\"he_normal\")(se)\\n        x = layers.Multiply()([x, se])\\n\\n    # 4. Project (Daraltma)\\n    x = layers.Conv2D(filters, (1, 1), strides=1, padding=\"same\",\\n                      kernel_initializer=\"he_normal\", use_bias=False)(x)\\n    x = layers.BatchNormalization()(x)\\n\\n    # 5. Shortcut Connection (Skip Connection)\\n    if stride == 1 and inputs.shape[-1] == filters:\\n        x = layers.Add()([inputs, x])\\n\\n    return x\\n\\n\\n\\ndef sigmachess_network(input_shape=(8, 8, 119)):\\n    inputs = layers.Input(shape=input_shape)\\n\\n    x = layers.Conv2D(256, (3, 3), strides=1, padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False)(inputs)\\n    x = layers.BatchNormalization()(x)\\n    x = layers.ReLU()(x)\\n\\n    for _ in range(19):\\n        x = EfficientNet_block(x)\\n\\n    policy = layers.Conv2D(256, (3, 3), strides=1, padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False)(x)\\n    policy = layers.BatchNormalization()(policy)\\n    policy = layers.ReLU()(policy)\\n    policy = layers.Conv2D(73, (1, 1), strides=1, padding=\"same\", kernel_initializer=\"he_normal\")(policy)\\n    policy = layers.Flatten()(policy)\\n    policy = layers.Softmax(name=\"policy_output\")(policy)\\n\\n    value = layers.Conv2D(1, (1, 1), strides=1, padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False)(x)\\n    value = layers.BatchNormalization()(value)\\n    value = layers.ReLU()(value)\\n    value = layers.Flatten()(value)\\n    value = layers.Dense(256, activation=\"relu\", kernel_initializer=\"he_normal\")(value)\\n    value = layers.Dense(1, activation=\"tanh\", name=\"value_output\", kernel_initializer=\"he_normal\")(value)\\n\\n    model = models.Model(inputs=inputs, outputs=[policy, value])\\n\\n    return model\\n\\ndef create_model():\\n    model = sigmachess_network()\\n\\n    model.compile(\\n        optimizer=Adam(learning_rate=0.00001),\\n        loss={\\n            \"policy_output\": \"categorical_crossentropy\",\\n            \"value_output\": \"mean_squared_error\"\\n        },\\n        metrics={\\n            \"policy_output\": \"accuracy\",\\n            \"value_output\": \"mse\"\\n        }\\n    )\\n\\n    return model\\n\\ndef play_vs_stockfish(model, game, replay_buffer):\\n    state = GameState()\\n    temperature = 1.0 if game < 5 else 0.1\\n\\n    w_states, w_policies, w_rewards = [], [], []\\n    player = np.random.choice([chess.WHITE, chess.BLACK])\\n\\n    engine = chess.engine.SimpleEngine.popen_uci(r\"/kaggle/working/stockfish-ubuntu-x86-64-avx2\")\\n\\n    while not state.is_terminal():\\n        if state.board.turn == player:\\n            mcts = MCTS(model, 1.0, 10)\\n            action_probs = mcts.run(state, temperature)\\n\\n            w_states.append(state.get_current_state())\\n            w_policies.append(action_probs)\\n\\n            action = np.random.choice(len(action_probs), p=action_probs)\\n            state.get_next_state(action)\\n        else:\\n            result = engine.play(state.board, chess.engine.Limit(0.04))\\n            state.apply_action(result.move)\\n\\n    engine.close()\\n\\n    winner = state.get_winner()\\n    w_value = 1 if winner == player else (0 if winner == 2 else -1)\\n\\n    print(player, state.board.board_fen())\\n\\n    replay_buffer.store_multiple_data(w_states, w_policies, w_value)\\n\\ndef self_play(model, num_games=100, max_workers=5):\\n    replay_buffer = ReplayBuffer(maxlen=500000)\\n\\n    with ThreadPoolExecutor(max_workers=max_workers) as executor:\\n        futures = [\\n            executor.submit(play_vs_stockfish, model, i, replay_buffer)\\n            for i in range(num_games)\\n        ]\\n\\n        for future in as_completed(futures):\\n            future.result()\\n\\n    print(\"Self-play completed\")\\n\\n    return replay_buffer\\n\\ndef prepare_validation_data(replay_buffer=None, filename=\"validation_data.npy\"):\\n    try:\\n        # First, try to load existing validation data\\n        data = np.load(filename, allow_pickle=True).item()\\n        print(f\"Loaded existing validation data from {filename}\")\\n        return data[\\'x_val\\'], {\\n            \"policy_output\": data[\\'y_val_policy\\'],\\n            \"value_output\": data[\\'y_val_value\\']\\n        }\\n    except (FileNotFoundError, IOError):\\n        # If no existing data, create new validation dataset\\n        if replay_buffer is None:\\n            # If no replay buffer provided, generate synthetic data\\n            x_val = np.random.random((100, 8, 8, 119))\\n            y_val_policy = np.random.randint(0, 73, size=(100, 1))\\n            y_val_value = np.random.random((100, 1)) * 2 - 1  # Values between -1 and 1\\n        else:\\n            # Use replay buffer to generate validation data\\n            states, policies, rewards = replay_buffer.sample(100)\\n            x_val = np.squeeze(states)\\n            y_val_policy = policies\\n            y_val_value = np.array(rewards).reshape(-1, 1)\\n\\n        # One-hot encode policy output\\n        y_val_policy_onehot = np.eye(73)[y_val_policy.flatten()]\\n\\n        # Prepare data dictionary\\n        validation_data = {\\n            \"x_val\": x_val,\\n            \"y_val_policy\": y_val_policy_onehot,\\n            \"y_val_value\": y_val_value\\n        }\\n\\n        # Save the validation data\\n        np.save(filename, validation_data)\\n        print(f\"Created and saved new validation data to {filename}\")\\n\\n        return x_val, {\\n            \"policy_output\": y_val_policy_onehot,\\n            \"value_output\": y_val_value\\n        }\\n\\ndef create_callbacks(checkpoint_path=\"kaggle/working/sigma_checkpoint.weights.h5\"):\\n    checkpoint = ModelCheckpoint(\\n        filepath=checkpoint_path,\\n        save_weights_only=True,\\n        monitor=\"loss\",\\n        mode=\"min\",\\n        save_best_only=True,\\n        save_freq=\"epoch\",\\n        verbose=1\\n    )\\n    return [checkpoint]\\n\\ndef train_model(model, replay_buffer: ReplayBuffer, batch_size=256, epochs=3, checkpoint_path=\"kaggle/working/sigma_checkpoint.weights.h5\"):\\n    x_val, y_val = prepare_validation_data()\\n\\n    callbacks = create_callbacks(checkpoint_path)\\n\\n    total_policy_loss = 0\\n    total_value_loss = 0\\n    epoch_count = 0\\n\\n    for epoch in range(epochs):\\n        states, policies, values = replay_buffer.sample(batch_size)\\n\\n        states = np.squeeze(states)\\n        if len(states.shape) == 3:\\n            states = np.expand_dims(states, -1)\\n\\n        values = np.array(values).reshape(-1, 1)\\n\\n        history = model.fit(\\n            states,\\n            { \"policy_output\": policies, \"value_output\": values },\\n            batch_size=batch_size,\\n            epochs=1,\\n            callbacks=callbacks,\\n            verbose=1\\n        )\\n\\n        total_policy_loss += history.history[\\'policy_output_loss\\'][0]\\n        total_value_loss += history.history[\\'value_output_loss\\'][0]\\n        epoch_count += 1\\n\\n    avg_policy_loss = total_policy_loss / epoch_count\\n    avg_value_loss = total_value_loss / epoch_count\\n\\n    print(f\"\\nAverage Policy Output Loss: {avg_policy_loss}\")\\n    print(f\"Average Value Output Loss: {avg_value_loss}\")\\n\\n    return avg_policy_loss, avg_value_loss\\n\\nis_stop = False\\n\\ndef train_sigmachess(model, num_iterations=100, num_games_per_iteration=100):\\n    global is_stop\\n\\n    # Değişkenleri başlatın\\n    total_policy_loss = 0\\n    total_value_loss = 0\\n    iteration_count = 0\\n\\n    for iteration in range(num_iterations):\\n        print(f\"Iteration {iteration + 1}/{num_iterations}\")\\n\\n        replay_buffer = self_play(model, num_games_per_iteration)\\n        policy_loss, value_loss = train_model(model, replay_buffer)\\n\\n        # Kayıpları biriktir\\n        total_policy_loss += policy_loss\\n        total_value_loss += value_loss\\n        iteration_count += 1\\n\\n        # Her 5 iteration\\'da bir ortalamaları yazdır\\n        if iteration_count % 5 == 0:\\n            avg_policy_loss = total_policy_loss / iteration_count\\n            avg_value_loss = total_value_loss / iteration_count\\n            print(f\"\\n[After {iteration_count} Iterations]\")\\n            print(f\"Average Policy Output Loss: {avg_policy_loss}\")\\n            print(f\"Average Value Output Loss: {avg_value_loss}\")\\n\\n        if is_stop:\\n            break\\n\\n    model.save(\"kaggle/working/full_model.keras\")\\n\\n\\ndef stop():\\n    global is_stop\\n\\n    while True:\\n        inp = input(\"\")\\n        if inp == \"stop\":\\n            is_stop = True\\n            print(\"After the iteration is completed, the training will be stopped and the model will be saved!\")\\n\\n            break\\n\\nt = threading.Thread(target=stop, daemon=True)\\nt.start()\\n\\nmodel = create_model()\\ntrain_sigmachess(model, num_iterations=7000, num_games_per_iteration=15)\\n\\n'"},"metadata":{}}],"execution_count":5},{"id":"2d16d318","cell_type":"markdown","source":"EARLY STOPPİNG ADD","metadata":{"id":"4LG1rw5vEDWT","papermill":{"duration":0.003558,"end_time":"2024-12-11T07:57:15.921560","exception":false,"start_time":"2024-12-11T07:57:15.918002","status":"completed"},"tags":[]}},{"id":"da221662","cell_type":"code","source":"\n\nimport numpy as np\nimport threading\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\n\ndef EfficientNet_block(inputs, filters=256, expansion_factor=6, stride=1, se_ratio=0.25):\n    \"\"\"\n    EfficientNet tarzı bir MBConv bloğu.\n\n    Args:\n        inputs: Giriş tensörü.\n        filters: Çıkış filtrelerinin sayısı.\n        expansion_factor: Genişletme oranı (Bottleneck genişletme için).\n        stride: Adım boyutu (ör. 1 veya 2).\n        se_ratio: Squeeze-and-Excitation (SE) oranı.\n\n    Returns:\n        EfficientNet MBConv bloğunun çıktısı.\n    \"\"\"\n    input_channels = inputs.shape[-1]  # Giriş kanal sayısı\n\n    # 1. Expand (Genişletme)\n    x = layers.Conv2D(input_channels * expansion_factor, (1, 1), strides=1, padding=\"same\",\n                      kernel_initializer=\"he_normal\", use_bias=False)(inputs)\n    x = layers.BatchNormalization()(x)\n    x = layers.ReLU()(x)\n\n    # 2. Depthwise Convolution (Derinlikçe Ayrık Evrişim)\n    x = layers.DepthwiseConv2D((3, 3), strides=stride, padding=\"same\",\n                               depthwise_initializer=\"he_normal\", use_bias=False)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.ReLU()(x)\n\n    # 3. Squeeze-and-Excitation (SE Blok)\n    if se_ratio:\n        se = layers.GlobalAveragePooling2D()(x)\n        se = layers.Reshape((1, 1, x.shape[-1]))(se)\n        se = layers.Conv2D(int(input_channels * se_ratio), (1, 1), activation=\"relu\", kernel_initializer=\"he_normal\")(se)\n        se = layers.Conv2D(x.shape[-1], (1, 1), activation=\"sigmoid\", kernel_initializer=\"he_normal\")(se)\n        x = layers.Multiply()([x, se])\n\n    # 4. Project (Daraltma)\n    x = layers.Conv2D(filters, (1, 1), strides=1, padding=\"same\",\n                      kernel_initializer=\"he_normal\", use_bias=False)(x)\n    x = layers.BatchNormalization()(x)\n\n    # 5. Shortcut Connection (Skip Connection)\n    if stride == 1 and inputs.shape[-1] == filters:\n        x = layers.Add()([inputs, x])\n\n    return x\n\n\n\ndef sigmachess_network(input_shape=(8, 8, 119)):\n    inputs = layers.Input(shape=input_shape)\n\n    x = layers.Conv2D(256, (3, 3), strides=1, padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False)(inputs)\n    x = layers.BatchNormalization()(x)\n    x = layers.ReLU()(x)\n\n    for _ in range(19):\n        x = EfficientNet_block(x)\n\n    policy = layers.Conv2D(256, (3, 3), strides=1, padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False)(x)\n    policy = layers.BatchNormalization()(policy)\n    policy = layers.ReLU()(policy)\n    policy = layers.Conv2D(73, (1, 1), strides=1, padding=\"same\", kernel_initializer=\"he_normal\")(policy)\n    policy = layers.Flatten()(policy)\n    policy = layers.Softmax(name=\"policy_output\")(policy)\n\n    value = layers.Conv2D(1, (1, 1), strides=1, padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False)(x)\n    value = layers.BatchNormalization()(value)\n    value = layers.ReLU()(value)\n    value = layers.Flatten()(value)\n    value = layers.Dense(256, activation=\"relu\", kernel_initializer=\"he_normal\")(value)\n    value = layers.Dense(1, activation=\"tanh\", name=\"value_output\", kernel_initializer=\"he_normal\")(value)\n\n    model = models.Model(inputs=inputs, outputs=[policy, value])\n\n    return model\n\ndef create_model(checkpoint_path=None):\n    model = sigmachess_network()\n\n    if checkpoint_path and os.path.exists(checkpoint_path):\n        print(f\"Loading weights from {checkpoint_path}\")\n        model.load_weights(checkpoint_path)\n    else:\n        print(\"No checkpoint found, initializing model with random weights.\")\n\n    model.compile(\n        optimizer=Adam(learning_rate=0.00001),\n        loss={\n            \"policy_output\": \"categorical_crossentropy\",\n            \"value_output\": \"mean_squared_error\"\n        },\n        metrics={\n            \"policy_output\": \"accuracy\",\n            \"value_output\": \"mse\"\n        }\n    )\n\n    return model\n\ndef play_vs_stockfish(model, game, replay_buffer):\n    state = GameState()\n    temperature = 1.0 if game < 5 else 0.1\n\n    w_states, w_policies, w_rewards = [], [], []\n    player = np.random.choice([chess.WHITE, chess.BLACK])\n\n    engine = chess.engine.SimpleEngine.popen_uci(r\"/kaggle/working/stockfish-ubuntu-x86-64-avx2\")\n\n    while not state.is_terminal():\n        if state.board.turn == player:\n            mcts = MCTS(model, 1.0, 10)\n            action_probs = mcts.run(state, temperature)\n\n            w_states.append(state.get_current_state())\n            w_policies.append(action_probs)\n\n            action = np.random.choice(len(action_probs), p=action_probs)\n            state.get_next_state(action)\n        else:\n            result = engine.play(state.board, chess.engine.Limit(0.04))\n            state.apply_action(result.move)\n\n    engine.close()\n\n    winner = state.get_winner()\n    w_value = 1 if winner == player else (0 if winner == 2 else -1)\n\n    print(player, state.board.board_fen())\n\n    replay_buffer.store_multiple_data(w_states, w_policies, w_value)\n\ndef self_play(model, num_games=100, max_workers=5):\n    replay_buffer = ReplayBuffer(maxlen=500000)\n\n    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n        futures = [\n            executor.submit(play_vs_stockfish, model, i, replay_buffer)\n            for i in range(num_games)\n        ]\n\n        for future in as_completed(futures):\n            future.result()\n\n    print(\"Self-play completed\")\n\n    return replay_buffer\n\ndef prepare_validation_data(replay_buffer=None, filename=\"validation_data.npy\"):\n    try:\n       \n        data = np.load(filename, allow_pickle=True).item()\n        print(f\"Loaded existing validation data from {filename}\")\n        return data['x_val'], {\n            \"policy_output\": data['y_val_policy'],\n            \"value_output\": data['y_val_value']\n        }\n    except (FileNotFoundError, IOError):\n        \n        if replay_buffer is None:\n            \n            x_val = np.random.random((100, 8, 8, 119))\n            y_val_policy = np.random.randint(0, 73, size=(100, 1))\n            y_val_value = np.random.random((100, 1)) * 2 - 1 \n        else:\n            \n            states, policies, rewards = replay_buffer.sample(100)\n\n            \n            y_val_policy = policies\n            y_val_value = np.array(rewards).reshape(-1, 1)\n\n       \n        y_val_policy_onehot = np.eye(73)[y_val_policy.flatten()]\n\n        # Prepare data dictionary\n        validation_data = {\n            \"x_val\": x_val,\n            \"y_val_policy\": y_val_policy_onehot,\n            \"y_val_value\": y_val_value\n        }\n\n        # Save the validation data\n        np.save(filename, validation_data)\n        print(f\"Created and saved new validation data to {filename}\")\n\n        return x_val, {\n            \"policy_output\": y_val_policy_onehot,\n            \"value_output\": y_val_value\n        }\n\ndef create_callbacks(checkpoint_path=\"kaggle/working/sigma_checkpoint.weights.h5\"):\n    checkpoint = ModelCheckpoint(\n        filepath=checkpoint_path,\n        save_weights_only=True,\n        monitor=\"loss\",\n        mode=\"min\",\n        save_best_only=True,\n        save_freq=\"epoch\",\n        verbose=1\n    )\n    return [checkpoint]\n\ndef train_model(model, replay_buffer: ReplayBuffer, batch_size=256, epochs=3, checkpoint_path=\"kaggle/working/sigma_checkpoint.weights.h5\"):\n    x_val, y_val = prepare_validation_data()\n\n    callbacks = create_callbacks(checkpoint_path)\n\n    total_policy_loss = 0\n    total_value_loss = 0\n    epoch_count = 0\n\n    for epoch in range(epochs):\n        states, policies, values = replay_buffer.sample(batch_size)\n\n        states = np.squeeze(states)\n        if len(states.shape) == 3:\n            states = np.expand_dims(states, -1)\n\n        values = np.array(values).reshape(-1, 1)\n\n        history = model.fit(\n            states,\n            { \"policy_output\": policies, \"value_output\": values },\n            batch_size=batch_size,\n            epochs=1,\n            callbacks=callbacks,\n            verbose=1\n        )\n\n        total_policy_loss += 0\n        total_value_loss += 0\n        epoch_count += 1\n\n    avg_policy_loss = total_policy_loss / epoch_count\n    avg_value_loss = total_value_loss / epoch_count\n\n   # print(f\"\\nAverage Policy Output Loss: {avg_policy_loss}\")\n   # print(f\"Average Value Output Loss: {avg_value_loss}\")\n\n    return avg_policy_loss, avg_value_loss\n\nis_stop = False\n\n\ndef train_sigmachess(model, num_iterations=100, num_games_per_iteration=100, checkpoint_path=\"kaggle/working/sigma_checkpoint.weights.h5\"):\n    global is_stop\n\n    \n    total_policy_loss = 0\n    total_value_loss = 0\n    iteration_count = 0\n\n    for iteration in range(num_iterations):\n        print(f\"Iteration {iteration + 1}/{num_iterations}\")\n\n        replay_buffer = self_play(model, num_games_per_iteration)\n        policy_loss, value_loss = train_model(model, replay_buffer, checkpoint_path=checkpoint_path)\n\n        # Kayıpları biriktirme kısmım\n        total_policy_loss += policy_loss\n        total_value_loss += value_loss\n        iteration_count += 1\n\n        # Her 5 iteration'da bir ortalamaları yazdırdım\n        if iteration_count % 5 == 0:\n            avg_policy_loss = total_policy_loss / iteration_count\n            avg_value_loss = total_value_loss / iteration_count\n            print(f\"\\n[After {iteration_count} Iterations]\")\n            print(f\"Average Policy Output Loss: {avg_policy_loss}\")\n            print(f\"Average Value Output Loss: {avg_value_loss}\")\n\n        if is_stop:\n            break\n\n    model.save(\"kaggle/working/full_model.keras\")\n\n\ndef stop():\n    global is_stop\n\n    while True:\n        inp = input(\"\")\n        if inp == \"stop\":\n            is_stop = True\n            print(\"After the iteration is completed, the training will be stopped and the model will be saved!\")\n\n            break\n\nt = threading.Thread(target=stop, daemon=True)\nt.start()\n\nmodel = create_model(r\"/kaggle/input/weight2/sigma_checkpoint.weights.h5\")\ntrain_sigmachess(model, num_iterations=7000, num_games_per_iteration=15)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-12-13T17:51:56.412730Z","iopub.execute_input":"2024-12-13T17:51:56.413159Z"},"id":"sDw_Ru4EPXCm","outputId":"9a9e0492-4d66-4695-cc39-a2278066a290","papermill":{"duration":null,"end_time":null,"exception":false,"start_time":"2024-12-11T07:57:15.925354","status":"running"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Loading weights from /kaggle/input/weight2/sigma_checkpoint.weights.h5\nIteration 1/7000\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1734112323.027566     103 service.cc:145] XLA service 0x79a5e0012ba0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1734112323.027659     103 service.cc:153]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1734112326.577539     103 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"False rnbqkbnr/1pppp2p/5p2/p5BQ/3PP3/8/PPP2PPP/RN2KBNR\nTrue rnb1kbnr/p4ppp/4p3/1pp5/1qpP4/2K1P3/P1Q2PPP/RNB2BNR\nFalse 3k1bB1/p2Qpp2/Ppr4p/2p1N1p1/3P4/8/PP3PPP/RNB2RK1\nFalse rn2k2R/1b1p1p2/2pP1B2/pp4P1/4P3/P1N2P2/1PP3P1/R1Q1KBN1\nTrue rnb1k2r/1pp2ppp/2R5/b2pp3/6B1/P7/3PPP2/1NBQK1q1\nFalse r5r1/p1pQk1pN/n6p/1B2PP2/8/b3BN2/PPP2PPP/R3R1K1\nFalse 3rk2r/p3B3/2pPP1Bb/1p6/7p/P2P1N2/1P2KPPP/RNQ4R\nTrue rn2kbnr/ppp2ppp/8/4p3/2PP2PP/PPp5/4PP2/R1BQK2q\nFalse 1nb1kQ2/1p1p4/rqp2pN1/p3p3/2BPP3/2N5/PPP2PPP/R1B1K2R\nTrue rnb1kbnr/ppp2ppp/8/3pq3/P2K4/2PP2P1/1P3P1P/RN2r2R\nTrue r2qk2r/ppp2ppp/2n5/1N6/1bPp2n1/1P1P2P1/PB3q1P/R2b1BKR\nTrue rnb1k2r/1p3ppp/2pb4/pq6/2KP2P1/PpP5/4Nn1P/7R\nTrue r3k1nr/p4ppp/p1n5/4pb2/Pb2q3/1P6/2p2PPP/R1BK2NR\nTrue r1b4r/ppp1kppp/2n5/3p3P/Pq6/2KPpP2/2P1Pn2/1NR2B2\nTrue r3k2r/1pp2pp1/8/2b3p1/2p2qb1/P1Ppn1K1/7P/2B2BR1\nSelf-play completed\nCreated and saved new validation data to validation_data.npy\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87s/step - loss: 4.5215 - policy_output_accuracy: 0.0167 - value_output_mse: 0.0012\nEpoch 1: loss improved from inf to 4.52150, saving model to kaggle/working/sigma_checkpoint.weights.h5\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 88s/step - loss: 4.5215 - policy_output_accuracy: 0.0167 - value_output_mse: 0.0012\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 3.9826 - policy_output_accuracy: 0.1333 - value_output_mse: 9.5647e-04\nEpoch 1: loss improved from 4.52150 to 3.98265, saving model to kaggle/working/sigma_checkpoint.weights.h5\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 3.9826 - policy_output_accuracy: 0.1333 - value_output_mse: 9.5647e-04   \n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 4.0220 - policy_output_accuracy: 0.0500 - value_output_mse: 7.3692e-04\nEpoch 1: loss did not improve from 3.98265\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 4.0220 - policy_output_accuracy: 0.0500 - value_output_mse: 7.3692e-04\nIteration 2/7000\nFalse r1bqk2r/ppppp1bP/6B1/3n4/8/5Q2/PPPP1PPP/RNB1K1NR\nTrue rnb1k1n1/ppp2pp1/8/3Bq3/2Pb1Kp1/N7/PP2P3/1RBr4\nTrue rn2k1nr/ppp2ppp/8/3p4/PbPQ4/1P2Kq2/5PbP/RN5R\nTrue rnb1k2r/pppp1ppp/8/8/P6P/1Pb1p3/2PN1qP1/R2QKBNR\nTrue r3k2r/ppp1nppp/8/3p4/PbPn4/5Pq1/2bN4/R1BK1B2\nTrue r3k2r/ppp2ppp/nb3n2/8/b3p1P1/5p1N/1R1PK2P/2q4R\nFalse rnR2b1r/3pkp1p/p1p5/1p2Q3/8/8/PPPP1PPP/RNB1KBNR\nTrue 4kb1r/rp2pppp/p1n2n2/3p4/1p3P1P/P5Pb/2PPP3/1RBQK1q1\nFalse rnb5/3p1p1p/1p2k1pn/p1pNQ3/4P3/5N2/PPP2PPP/R1B1KB1R\nFalse r4b1r/pp1Qp1p1/nk1pPpB1/2p4p/N2P4/5N2/PPPB1PPP/R3K2R\nTrue r2qk2r/ppp2ppp/8/3p4/P3bpnP/2N1b2N/RPn1P1PK/3Q1B1R\nTrue rnb1k2r/ppp2ppp/8/4p3/n1P4P/4qP1N/PK2P1PR/3q1B2\nTrue rn2k2r/pppb1ppp/4p3/3p4/PP3b2/3Kq3/2P1P2P/RN6\nTrue r1b3k1/pp3ppp/2n2n2/b1p5/5P1P/B1P1K1P1/P7/RN2qq2\nFalse 7r/p2Pn1Qk/1pBpNp1p/6p1/2p1P2P/4B3/PPP2PP1/R3K1NR\nSelf-play completed\nLoaded existing validation data from validation_data.npy\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 5.6012 - policy_output_accuracy: 0.0333 - value_output_mse: 0.0013\nEpoch 1: loss improved from inf to 5.60117, saving model to kaggle/working/sigma_checkpoint.weights.h5\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 5.6012 - policy_output_accuracy: 0.0333 - value_output_mse: 0.0013   \n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 5.5768 - policy_output_accuracy: 0.0333 - value_output_mse: 0.0012\nEpoch 1: loss improved from 5.60117 to 5.57676, saving model to kaggle/working/sigma_checkpoint.weights.h5\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 5.5768 - policy_output_accuracy: 0.0333 - value_output_mse: 0.0012   \n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 5.3677 - policy_output_accuracy: 0.0667 - value_output_mse: 0.0012\nEpoch 1: loss improved from 5.57676 to 5.36773, saving model to kaggle/working/sigma_checkpoint.weights.h5\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 5.3677 - policy_output_accuracy: 0.0667 - value_output_mse: 0.0012   \nIteration 3/7000\nTrue rnb1kbnr/ppp2ppp/8/3pp3/P5Pq/5P2/1PPPP2P/RNBQKBNR\nFalse rnb1kb1r/1pNq1p1p/4p2n/pBP3B1/4P3/8/PPP2PPP/R2QK1NR\nTrue r3kbnr/ppp2pp1/1Pn5/4p3/5B1p/N1P2PP1/P3q2P/R3Kb2\nTrue r3k1nr/ppp2ppp/2n5/4p3/2p3b1/N1b5/P2qPP1P/R2K1BNR\nTrue rn1q1rk1/pp3ppp/2pb1n2/K2p4/2PP3P/P5P1/1Pq1PP2/R1B5\nTrue r3r1k1/ppp2ppp/5n1b/1P6/2n3P1/2PpP2P/P2B1Pb1/R3K1q1\nTrue r3k1nr/ppp2pp1/2n5/2bppb2/2P1PPp1/7P/PP1P1q2/1RBQKBN1\nFalse 1rb3n1/kpp5/4p1P1/RPPpN3/3P3q/3BBN2/1P3PP1/3QK2R\nTrue rn2k2r/pp3ppp/2p2n2/3pp3/P3P3/8/1PQPbqPP/RNB1K1bR\nTrue r1b1k2r/pp3ppp/2n2n2/P2q4/2Kpp3/1Pb5/2P1PPPP/R1BQ1BNR\nFalse 1nbq1bnN/rppk4/3pQp1p/3P2p1/p3P3/2N5/PPP2PPP/R1B1KB1R\nFalse rnbqkbn1/1p1pp3/5pQ1/p1pP4/P3P3/8/1PP2PPP/RNB1K1NR\nTrue r1b1k1nr/ppp1qpPp/2n5/4p3/8/3Pb1PN/1P2P2R/2r1KB2\nTrue rn2k2r/ppp2ppp/4b3/1P2p3/5q2/3PK2P/P3P1P1/RNBQ1BNn\nFalse 6r1/2pkBP1p/p3Q1p1/p2p1p2/1q6/P4N2/1PP2PPP/RN2R1K1\nSelf-play completed\nLoaded existing validation data from validation_data.npy\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 4.7086 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 0.0012\nEpoch 1: loss improved from inf to 4.70862, saving model to kaggle/working/sigma_checkpoint.weights.h5\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 4.7086 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 0.0012   \n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 4.8722 - policy_output_accuracy: 0.0333 - value_output_mse: 0.0013\nEpoch 1: loss did not improve from 4.70862\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 4.8722 - policy_output_accuracy: 0.0333 - value_output_mse: 0.0013\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 3.8640 - policy_output_accuracy: 0.2000 - value_output_mse: 8.1114e-04\nEpoch 1: loss improved from 4.70862 to 3.86399, saving model to kaggle/working/sigma_checkpoint.weights.h5\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 3.8640 - policy_output_accuracy: 0.2000 - value_output_mse: 8.1114e-04   \nIteration 4/7000\nFalse r1bqkb1r/ppppp2P/2n5/5n1Q/8/3B4/PPPP1PPP/RNB1K1NR\n","output_type":"stream"},{"name":"stdout","output_type":"stream","text":["True rn2kb1r/pp2pppp/8/3p4/3P1P2/Pb5N/2q1P2P/RK3B1R\n"]},{"name":"stdout","output_type":"stream","text":["False r2k1bnr/4ppp1/bN6/1Bp5/4PB1p/5N2/PPPQ1PPP/R3K2R\n"]},{"name":"stdout","output_type":"stream","text":["True r1b1kb1r/pp1p1ppp/8/q1p1p3/1nP5/KP2P2P/P2P2P1/RNBn1BNR\n"]},{"name":"stdout","output_type":"stream","text":["False 5Q1Q/2p1kp2/4p2p/8/p7/2N1B3/PPP2PPP/3RK1NR\n"]},{"name":"stdout","output_type":"stream","text":["True r3r1k1/ppp2ppp/2n2n2/2P5/6bP/bP3p2/P3P1qK/6NR\n"]},{"name":"stdout","output_type":"stream","text":["True rn1qk1nr/p1p2ppp/1p6/3p4/2bpP3/2bK2P1/P1P2P1P/R1BQ1BNR\n"]},{"name":"stdout","output_type":"stream","text":["False 1nbq1brk/1p1ppN2/6Q1/p1p3p1/3PP2p/P1N1B3/1PP2PPP/R3K2R\n"]},{"name":"stdout","output_type":"stream","text":["True 1r3k1r/2p2pp1/p2b1n2/2pp1bp1/3P1p2/NqP1P1P1/KP5P/R1B2BR1\n"]},{"name":"stdout","output_type":"stream","text":["True r3r1k1/ppp2pp1/2nb1n2/3p2p1/5P2/PPPP2Pb/3B2q1/RN4K1\n"]},{"name":"stdout","output_type":"stream","text":["False rnb3kr/3pBpQ1/1p5p/p1P3pN/4P3/8/P1P2PPP/R3KBNR\n"]},{"name":"stdout","output_type":"stream","text":["True r1b1k2r/ppp2ppp/2n5/4b3/2p4P/PP2p3/3q2P1/2RK1BNn\n"]},{"name":"stdout","output_type":"stream","text":["False Q2Q1bn1/p1k2p1r/1p4p1/4N2p/1P1P4/2N5/1PP2PPP/R1B2RK1\n","Self-play completed\n","Created and saved new validation data to validation_data.npy\n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76s/step - loss: 6.3334 - policy_output_accuracy: 0.1000 - value_output_mse: 0.0020"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from inf to 6.33340, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 78s/step - loss: 6.3334 - policy_output_accuracy: 0.1000 - value_output_mse: 0.0020\n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 6.0125 - policy_output_accuracy: 0.2000 - value_output_mse: 0.0020"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from 6.33340 to 6.01247, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 6.0125 - policy_output_accuracy: 0.2000 - value_output_mse: 0.0020   \n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 6.2043 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 0.0020"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss did not improve from 6.01247\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 6.2043 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 0.0020\n"]},{"name":"stdout","output_type":"stream","text":["Iteration 2/7000\n"]},{"name":"stdout","output_type":"stream","text":["False rnbq1bnr/1pppB1pp/p7/4Q3/3Pk3/8/PPP2PPP/RN2KBNR\n"]},{"name":"stdout","output_type":"stream","text":["False 1nbq1b1r/rp1pkB1p/3Q1n2/p1P1N1B1/4P3/8/PPP2PPP/RN2K2R\n"]},{"name":"stdout","output_type":"stream","text":["False 4kbnr/rpBQ1p1p/8/pB2p3/4P3/2N5/PPP2PPP/R3K1NR\n"]},{"name":"stdout","output_type":"stream","text":["True rnb2rk1/ppp2ppp/8/4p3/P3n3/1P2P1PP/2Pq1PR1/1R2KBN1\n"]},{"name":"stdout","output_type":"stream","text":["False 1nk2b1r/2Q3p1/p1p1pp1p/Bp6/3PP3/P2B1N2/P1P1KPPP/R6R\n"]},{"name":"stdout","output_type":"stream","text":["False rnb3nN/1p1pb1p1/p4k1p/2p2Q2/4P3/2N5/PPP2PPP/R1B1KB1R\n"]},{"name":"stdout","output_type":"stream","text":["False 1n3b1r/2p3pp/4Q2B/4Pp2/7k/2N2BP1/1PP2P1P/R3K1NR\n"]},{"name":"stdout","output_type":"stream","text":["False rn1k1Q2/p1pp4/bp2p2p/6N1/3PP3/8/PPP2PPP/RN2KB1R\n"]},{"name":"stdout","output_type":"stream","text":["False 1rbqkQ2/p2npp1p/2B2P1B/3p4/3P4/2N5/PPP2PPP/R3K1NR\n"]},{"name":"stdout","output_type":"stream","text":["False r1b4r/2BnkQp1/1p2p2p/pB6/3P4/P3P2N/P1P3PP/R4RK1\n"]},{"name":"stdout","output_type":"stream","text":["True r3r2k/p4ppp/p7/b1p1p1P1/2P2n2/4p2P/b2P4/2q1K1NR\n"]},{"name":"stdout","output_type":"stream","text":["False r2qkbnN/p2bp3/1pB2pQ1/2pp4/3PP3/8/PPP2PPP/RNB1K2R\n"]},{"name":"stdout","output_type":"stream","text":["True r1b4r/p1p1k1pp/p2b4/2n1p3/1n1p3P/8/1PKP1PP1/1NB2qNR\n"]},{"name":"stdout","output_type":"stream","text":["False 1nb1Qbr1/3p2p1/r1p2k1p/p3Bp2/1p1P4/2NB1P1N/PPP2KPP/4R2R\n"]},{"name":"stdout","output_type":"stream","text":["True r1b4r/pp2kppp/3bp3/2Pp4/4nP2/P2pP2P/6PR/1q1K2N1\n","Self-play completed\n","Loaded existing validation data from validation_data.npy\n","\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 5.7113 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 0.0014"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from inf to 5.71132, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 5.7113 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 0.0014   \n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 6.2207 - policy_output_accuracy: 0.0333 - value_output_mse: 0.0062"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss did not improve from 5.71132\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 6.2207 - policy_output_accuracy: 0.0333 - value_output_mse: 0.0062\n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 5.3489 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 0.0020"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from 5.71132 to 5.34886, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 5.3489 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 0.0020   \n"]},{"name":"stdout","output_type":"stream","text":["Iteration 3/7000\n"]},{"name":"stdout","output_type":"stream","text":["False rnbqkbnr/1pppp2p/p7/5PpQ/3P4/8/PPP2PPP/RNB1KBNR\n"]},{"name":"stdout","output_type":"stream","text":["False rnbq4/1p1pkQbP/7p/p1P1N3/2B5/2N5/PPP2PPP/R1B1K2R\n","True rn2kbnr/ppp2pp1/8/4p2p/1P3PP1/P7/2PPP1qP/R1BQ2Kb\n"]},{"name":"stdout","output_type":"stream","text":["False rnbqkbnr/ppppp3/6Qp/5P2/8/8/PPPP1PPP/RNB1KBNR\n"]},{"name":"stdout","output_type":"stream","text":["True r2r2k1/ppp2pbp/7p/2n1p3/P3n1P1/N1P2K2/1P3q1P/R4B1R\n"]},{"name":"stdout","output_type":"stream","text":["False rnbqkbnr/p1ppp2P/8/1p5Q/8/8/PPPP1PPP/RNB1KBNR\n"]},{"name":"stdout","output_type":"stream","text":["False r5r1/2p2Qbp/p3Bpk1/4p3/8/2N2N2/PP3PPP/R1B1K2R\n"]},{"name":"stdout","output_type":"stream","text":["True r4b1r/pppk3p/4pp2/6p1/1Pp5/P1nNP3/3q4/RK2R3\n"]},{"name":"stdout","output_type":"stream","text":["False rnbN1b1r/3p2kp/p7/2p3Q1/1p1PP3/1B6/PPP2PPP/RN2K2R\n"]},{"name":"stdout","output_type":"stream","text":["True rn2kb1r/ppp2p1p/4bp2/4p3/1PP3qK/N7/P2P3P/R1B3NR\n"]},{"name":"stdout","output_type":"stream","text":["True r4k1r/2p2ppp/1p3n2/p3pP1b/2pqn3/3PK1PN/2P4P/R4B2\n"]},{"name":"stdout","output_type":"stream","text":["False 3R1b1r/2r3p1/2P1k2p/3NpQ2/1P2P3/8/1PPB1PPP/1N2K2R\n"]},{"name":"stdout","output_type":"stream","text":["True r1b1k2r/pp3ppp/4p2n/2p5/2P5/PP1BqK2/2p1N1PP/R1b4R\n"]},{"name":"stdout","output_type":"stream","text":["True r1b1kb1r/pp1ppppp/5n2/2P5/2P1P2P/Pn4P1/3q1P2/4KBNR\n"]},{"name":"stdout","output_type":"stream","text":["True r3k2r/ppp1bppp/n4n2/3p3b/PP2P2P/2P5/3B1P2/RN1qK1NR\n","Self-play completed\n","Loaded existing validation data from validation_data.npy\n","\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 6.2481 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 0.0025"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from inf to 6.24813, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 6.2481 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 0.0025   \n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 5.3739 - policy_output_accuracy: 0.0500 - value_output_mse: 0.0018"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from 6.24813 to 5.37389, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 5.3739 - policy_output_accuracy: 0.0500 - value_output_mse: 0.0018   \n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 5.0768 - policy_output_accuracy: 0.0167 - value_output_mse: 0.0012"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from 5.37389 to 5.07680, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 5.0768 - policy_output_accuracy: 0.0167 - value_output_mse: 0.0012   \n"]},{"name":"stdout","output_type":"stream","text":["Iteration 4/7000\n"]},{"name":"stdout","output_type":"stream","text":["True rnb1kbnr/pppp1ppp/8/2P5/7q/N7/PP1PP1pP/R1BQKBNR\n"]},{"name":"stdout","output_type":"stream","text":["False rnbq1br1/pppp2p1/2k4p/3Q1p2/2NPP3/8/PPP2PPP/RNB1KB1R\n"]},{"name":"stdout","output_type":"stream","text":["False 2QQk1r1/5p1p/1rp1pP1B/pB6/8/5N2/PPP2PPP/RN2K2R\n"]},{"name":"stdout","output_type":"stream","text":["True rnb1kbnr/ppp2ppp/8/3p4/3q4/N3q3/PPP3PP/RQK2B1R\n"]},{"name":"stdout","output_type":"stream","text":["True 1r2kb1r/p1p2pp1/2n5/p2p3p/1P2pP2/2PKP1nP/P2B4/RN1q4\n"]},{"name":"stdout","output_type":"stream","text":["True r3k2r/1pp1bpp1/2n2n2/3p3p/4p2P/PpP1P1P1/1KqP4/R1B5\n"]},{"name":"stdout","output_type":"stream","text":["True rnb1k1nr/ppp2ppp/8/2bKp3/3q4/7P/PPPP2P1/RNBQ1BNR\n"]},{"name":"stdout","output_type":"stream","text":["True r3k2r/pp4p1/n4p2/b1p2b1P/5B1P/PP2pPn1/3q4/R1K3NR\n"]},{"name":"stdout","output_type":"stream","text":["False 3k2nr/p2Q4/4pp2/1Bp3bp/4P3/4BN2/PPP2PPP/RN2K2R\n"]},{"name":"stdout","output_type":"stream","text":["True rn2kb1r/ppp2ppp/8/3ppb2/P4P2/2PK4/1PQP1q1P/RNB3Nn\n"]},{"name":"stdout","output_type":"stream","text":["True 2r1k2r/pp1b1pbp/8/P2p4/R1nP1p1q/5P1P/2n1P3/KNn2BN1\n"]},{"name":"stdout","output_type":"stream","text":["True r3kbnr/ppp2ppp/8/3p4/3nb3/P3P3/1P3P2/RNq1K3\n"]},{"name":"stdout","output_type":"stream","text":["False r4kn1/3p1Q2/p1pNp2p/q3P3/3P2P1/1p1B4/1PP2PPN/R4RK1\n"]},{"name":"stdout","output_type":"stream","text":["False 1R3b1r/1Qk5/6pp/P1P5/2B2p1R/4B3/P1P1NPP1/4K3\n"]},{"name":"stdout","output_type":"stream","text":["True rn2k1nr/ppp2ppp/8/3p4/2P5/3bPpqP/PP1P4/1RB2K2\n","Self-play completed\n","Loaded existing validation data from validation_data.npy\n","\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 5.3355 - policy_output_accuracy: 0.1000 - value_output_mse: 0.0021"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from inf to 5.33550, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 5.3355 - policy_output_accuracy: 0.1000 - value_output_mse: 0.0021   \n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 5.6873 - policy_output_accuracy: 0.0333 - value_output_mse: 0.0021"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss did not improve from 5.33550\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 5.6873 - policy_output_accuracy: 0.0333 - value_output_mse: 0.0021\n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 5.9285 - policy_output_accuracy: 0.1000 - value_output_mse: 0.0021"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss did not improve from 5.33550\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 5.9285 - policy_output_accuracy: 0.1000 - value_output_mse: 0.0021\n"]},{"name":"stdout","output_type":"stream","text":["Iteration 5/7000\n"]},{"name":"stdout","output_type":"stream","text":["True 2b1k2r/1pp2ppp/5n2/4pn1B/4p3/2b3P1/3qKP1P/2r3NR\n"]},{"name":"stdout","output_type":"stream","text":["False 2Q1k1r1/1p2pp1p/2p2PpB/2NpN3/3P4/8/PPP1BPPP/R2K3R\n"]},{"name":"stdout","output_type":"stream","text":["True 4kb2/r5p1/1pn2np1/2p1p1pr/2P3b1/P4p2/1P2q3/RNB1K2R\n"]},{"name":"stdout","output_type":"stream","text":["False 1r1q1b2/p1ppN3/Bp3p1p/2k5/2Q1PB1P/5N2/PPP2PP1/R3K2R\n"]},{"name":"stdout","output_type":"stream","text":["False 4k3/p4Qp1/3bB3/6Bp/3P2P1/P1N2N2/P1P2PP1/R3K2R\n"]},{"name":"stdout","output_type":"stream","text":["True rnb1kbnr/pppp1ppp/8/4p3/8/5PqP/PPPPP3/RNBQKBNR\n"]},{"name":"stdout","output_type":"stream","text":["True rn2k2r/1ppq1ppp/8/pKnpp3/3b2bP/P7/1PPP4/RNBQ1BNR\n"]},{"name":"stdout","output_type":"stream","text":["True r2q2k1/1pp2pp1/p2b1n2/7p/P1p2p2/R2n2PP/2KP1P2/1Nr4b\n"]},{"name":"stdout","output_type":"stream","text":["True 2bqk2r/1pp2pp1/2n2n2/3pp2p/2P1P3/2bP1PPB/r6P/3q1KNR\n"]},{"name":"stdout","output_type":"stream","text":["False r1b2bnr/2k3p1/pQ2Pp2/1B1P3p/8/2N1BN2/1PP2PPP/R3K2R\n"]},{"name":"stdout","output_type":"stream","text":["False r1bqkbnr/pp1pp2P/n7/2p4Q/8/8/PPPP1PPP/RNB1KBNR\n"]},{"name":"stdout","output_type":"stream","text":["False r1bq1b1r/1pppp2p/5k1B/p4Q2/P3P3/2N5/1PP2PPP/R3KBNR\n"]},{"name":"stdout","output_type":"stream","text":["False 1rb2B1r/pp2Pp1p/1np3p1/3p4/k2P4/Q2B4/PPP2PPP/R3K1NR\n"]},{"name":"stdout","output_type":"stream","text":["False 5Qnr/3Bp3/5kpp/p1p1Np2/3P1B2/8/PPP2PPP/R2QK2R\n"]},{"name":"stdout","output_type":"stream","text":["False 3k3r/pp1B3p/4pB2/2P1Q3/4P3/5N2/PPP2PPP/3RK2R\n","Self-play completed\n","Loaded existing validation data from validation_data.npy\n","\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 6.1138 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 0.0012"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from inf to 6.11377, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 6.1138 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 0.0012   \n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 5.5914 - policy_output_accuracy: 0.0167 - value_output_mse: 0.0019"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from 6.11377 to 5.59141, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 5.5914 - policy_output_accuracy: 0.0167 - value_output_mse: 0.0019   \n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 6.2696 - policy_output_accuracy: 0.0333 - value_output_mse: 0.0256"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss did not improve from 5.59141\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 6.2696 - policy_output_accuracy: 0.0333 - value_output_mse: 0.0256\n"]},{"name":"stdout","output_type":"stream","text":["\n","[After 5 Iterations]\n","Average Policy Output Loss: 0.0\n","Average Value Output Loss: 0.0\n","Iteration 6/7000\n"]},{"name":"stdout","output_type":"stream","text":["True rnb1kbnr/ppp2ppp/8/3p4/3p4/7P/PPP1PPP1/RNq1KBNR\n"]},{"name":"stdout","output_type":"stream","text":["True r3k1nr/1pp2ppp/p1n5/P3p3/2q3Pb/5P1b/1P1PP3/2BQK3\n"]},{"name":"stdout","output_type":"stream","text":["True rn2k2r/ppp2ppp/3p1n2/4p3/PbP3bP/6q1/3P4/RNBQKB2\n"]},{"name":"stdout","output_type":"stream","text":["True rn2k1nr/1pp2ppp/p7/P3p3/2P1P3/1b1K4/2Nq3P/2b2B1R\n"]},{"name":"stdout","output_type":"stream","text":["True r3k2r/pp2b2p/2n2p2/3p4/1P1pnP1P/4Pb2/1PP5/RNK3q1\n"]},{"name":"stdout","output_type":"stream","text":["False 4kb1r/2pQ3p/B3Pppn/8/4P3/2N1BN1P/PP3PP1/R3K2R\n"]},{"name":"stdout","output_type":"stream","text":["False rnbq1b2/pppkp2p/8/3Q3Q/8/8/PPPP1PPP/RNB1KBNR\n"]},{"name":"stdout","output_type":"stream","text":["False rnbqkbnr/ppppp2p/5p2/6pQ/3PP3/8/PPP2PPP/RNB1KBNR\n"]},{"name":"stdout","output_type":"stream","text":["True r1b1k1r1/pp1ppp1p/4nn2/2p5/2P1P3/2b5/P3NP1P/3q1K1R\n"]},{"name":"stdout","output_type":"stream","text":["False 2rq1b1r/3k1Ppp/1pp1Q1n1/p4P2/3P1B2/P1N2N2/1PP3PP/R4RK1\n"]},{"name":"stdout","output_type":"stream","text":["True rnb1kbnr/ppp2ppp/8/3pp3/8/P4PqP/1PPPP3/RNBQKBNR\n"]},{"name":"stdout","output_type":"stream","text":["True r5k1/pp3ppp/n4n2/8/1bPq2P1/B2p1P1P/P7/RNK1r3\n"]},{"name":"stdout","output_type":"stream","text":["True rnb1k2r/ppp2ppp/5n2/8/P3p3/2B3P1/4PP1P/r2qKB1R\n"]},{"name":"stdout","output_type":"stream","text":["True 2b1k2r/4bpp1/1p2p1p1/np2p3/r4nP1/1K3P1P/P1P5/q1B2Q2\n"]},{"name":"stdout","output_type":"stream","text":["True r3kbnr/pp3ppp/2n5/2pp4/P5b1/R2P4/1PP2q2/1NBK4\n","Self-play completed\n","Loaded existing validation data from validation_data.npy\n","\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 5.0946 - policy_output_accuracy: 0.0333 - value_output_mse: 0.0020"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from inf to 5.09458, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 5.0946 - policy_output_accuracy: 0.0333 - value_output_mse: 0.0020   \n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 5.5618 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 0.0289"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss did not improve from 5.09458\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 5.5618 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 0.0289\n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 5.7782 - policy_output_accuracy: 0.0667 - value_output_mse: 0.0822"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss did not improve from 5.09458\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 5.7782 - policy_output_accuracy: 0.0667 - value_output_mse: 0.0822\n"]},{"name":"stdout","output_type":"stream","text":["Iteration 7/7000\n"]},{"name":"stdout","output_type":"stream","text":["True r1b1kbnr/pp3pp1/2n5/2p1p2p/P4PPq/1P2p3/R1PPP2P/1NBQKB1R\n"]},{"name":"stdout","output_type":"stream","text":["True r3k2r/1pp2ppp/2n5/p2np3/1bPp3q/5P2/PB1PP3/RN1QKB1b\n"]},{"name":"stdout","output_type":"stream","text":["True r3k2r/ppp2ppp/2n2n2/4p2P/P4P2/3B4/1Pbb2q1/R3K1NR\n"]},{"name":"stdout","output_type":"stream","text":["False 5b1r/4p1p1/k1Q2p1n/pNP4p/5B2/8/PPP2PPP/R3K2R\n"]},{"name":"stdout","output_type":"stream","text":["True rn2kb1r/ppp2ppp/8/3p4/1P2q1n1/2PK2Pb/P2P3P/RNBQ3R\n"]},{"name":"stdout","output_type":"stream","text":["True rnb1k2r/pp2ppbp/7p/3p4/P2p3P/2P5/R2KP1P1/1q3nNR\n"]},{"name":"stdout","output_type":"stream","text":["True r3kbnr/pp1bpppp/1q6/8/2np4/K1P1p3/PP2PPPP/RN1Q1BNR\n"]},{"name":"stdout","output_type":"stream","text":["True 4r1k1/1p3pp1/2n2n2/r3p1p1/1KP1b3/N2q2P1/PB1ppP1P/1R5R\n"]},{"name":"stdout","output_type":"stream","text":["False rnbqkbnr/1pppp2p/p4p2/6pB/3PP3/8/PPP2PPP/RNBQK1NR\n"]},{"name":"stdout","output_type":"stream","text":["False rnb3nr/1pk2pp1/p2QP3/2P4p/8/2N5/PPP2PPP/R3KBNR\n"]},{"name":"stdout","output_type":"stream","text":["True rnb1kb1r/pp3ppp/2p5/3p4/3Pn3/PP2P3/2P2q1P/RNBQKB1q\n"]},{"name":"stdout","output_type":"stream","text":["False 2bR3r/1p1p3p/3Qk2B/p1p1Pp1B/8/2N5/PPP2PPP/R3K1NR\n"]},{"name":"stdout","output_type":"stream","text":["False r2k2nr/p1pQ3p/4Bp1P/2p5/1P2PN2/2N1B3/1PP2PP1/3RK2R\n"]},{"name":"stdout","output_type":"stream","text":["True 1r3b1r/p1pk1ppp/p1n5/8/2P5/PPKp4/2q2pP1/1NB4R\n"]},{"name":"stdout","output_type":"stream","text":["False 3k4/7R/pNBp1B2/5p2/1p4P1/8/PPP2PP1/RN2K3\n","Self-play completed\n","Loaded existing validation data from validation_data.npy\n","\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 5.7295 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 0.0018"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from inf to 5.72953, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 5.7295 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 0.0018   \n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 7.0971 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 0.0066"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss did not improve from 5.72953\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 7.0971 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 0.0066\n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 5.4820 - policy_output_accuracy: 0.1000 - value_output_mse: 0.0015"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from 5.72953 to 5.48204, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 5.4820 - policy_output_accuracy: 0.1000 - value_output_mse: 0.0015   \n"]},{"name":"stdout","output_type":"stream","text":["Iteration 8/7000\n"]},{"name":"stdout","output_type":"stream","text":["True rnb1k1nr/ppp2ppp/8/2bpp1q1/8/P4PK1/1PPPP1PP/RNBQ1BNR\n"]},{"name":"stdout","output_type":"stream","text":["False rnbqkbnr/ppppp2p/5p2/6pQ/3PP3/8/PPP2PPP/RNB1KBNR\n"]},{"name":"stdout","output_type":"stream","text":["True 2b1k1nr/rpp2ppp/2np4/4p2P/1bP5/7B/P2PPP2/RNq1K1NR\n"]},{"name":"stdout","output_type":"stream","text":["False rnbqk1nr/ppppb1Pp/4p3/7Q/8/8/PPPP1PPP/RNB1KBNR\n"]},{"name":"stdout","output_type":"stream","text":["False Q3kb1r/3bppp1/7p/pBP2n2/8/2N2N2/PPP2PPP/R1Bq1RK1\n"]},{"name":"stdout","output_type":"stream","text":["False N1Q1kBnr/1p1n1p1p/8/p3PP2/4P1p1/8/PPP3PP/R3KBNR\n"]},{"name":"stdout","output_type":"stream","text":["True rnb1kb1r/pppp1ppp/8/4p3/1P3Pnq/8/PBPPP2P/RN1QKBNR\n"]},{"name":"stdout","output_type":"stream","text":["False r1b1Q1n1/1p3Qb1/3k4/pN2ppPp/2B1P3/4B3/PPP2PP1/R3K1NR\n"]},{"name":"stdout","output_type":"stream","text":["False r1bqkb1r/p2ppQ2/n1p2P1p/1p4N1/3P4/8/PPP2PPP/RNB1KB1R\n"]},{"name":"stdout","output_type":"stream","text":["False rn1Qk2r/2p1Pppp/p1b4B/1B6/4P3/2N5/PPP2PPP/R3K1NR\n"]},{"name":"stdout","output_type":"stream","text":["True rn1k1b1r/ppp2ppp/5n2/4p3/P3p3/2N1PPPb/3PK2P/5q2\n"]},{"name":"stdout","output_type":"stream","text":["True rn1qk2r/ppp2ppp/8/3pp3/4n1b1/P1P5/1P1P1bPP/RNBQKB1R\n"]},{"name":"stdout","output_type":"stream","text":["False 1rb2br1/pp1p2p1/2N1k1B1/6Bp/8/q1N5/PPP2PPP/R2QR1K1\n"]},{"name":"stdout","output_type":"stream","text":["True r1b2rk1/pp3pbp/5pp1/8/1pPn4/2qP3P/PK3pPR/RQ3B2\n"]},{"name":"stdout","output_type":"stream","text":["True r4rk1/ppp2ppp/1n3n2/4p1N1/K3pP2/3q4/P4P1P/2B1b2R\n","Self-play completed\n","Loaded existing validation data from validation_data.npy\n","\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 4.5275 - policy_output_accuracy: 0.1667 - value_output_mse: 0.0015"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from inf to 4.52751, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 4.5275 - policy_output_accuracy: 0.1667 - value_output_mse: 0.0015   \n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 4.2582 - policy_output_accuracy: 0.1667 - value_output_mse: 0.0013"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from 4.52751 to 4.25816, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 4.2582 - policy_output_accuracy: 0.1667 - value_output_mse: 0.0013   \n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 5.1407 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 0.0014"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss did not improve from 4.25816\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 5.1407 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 0.0014\n"]},{"name":"stdout","output_type":"stream","text":["Iteration 9/7000\n"]},{"name":"stdout","output_type":"stream","text":["False rnbq1b1r/1pk1p1pp/3p4/pBpN1P1Q/3P4/4B3/PPP2PPP/R3K1NR\n"]},{"name":"stdout","output_type":"stream","text":["False 2R3nr/3p1kp1/2pQ4/1p4Np/1p2P3/8/1PP2PPP/1N2KB1R\n"]},{"name":"stdout","output_type":"stream","text":["False 4Qb1r/r2k1p2/5Bp1/p1PN3p/8/5N1P/P1P2PP1/R2QRbK1\n"]},{"name":"stdout","output_type":"stream","text":["True r2qk2r/ppp2ppp/2n1b3/4p3/Pb5P/1KpPnPP1/RP2P3/1NBQ1BNR\n"]},{"name":"stdout","output_type":"stream","text":["True r3k2r/ppp2ppn/3b1n2/2P5/PP1p3P/6p1/R1bPPK2/2B4q\n"]},{"name":"stdout","output_type":"stream","text":["False r1bqkb1r/p1ppp1p1/2B3Q1/7p/3PP3/8/PPP2PPP/RNB1K1NR\n"]},{"name":"stdout","output_type":"stream","text":["False 1k6/1Q6/6N1/pppBP1B1/1n1P2P1/8/PPP2PP1/2KR3R\n"]},{"name":"stdout","output_type":"stream","text":["True rnb1k1nr/p4pp1/1pp5/2b3p1/P1P4P/2NPp3/5q2/1R1QKBNR\n"]},{"name":"stdout","output_type":"stream","text":["False rn1q1b1r/1pp1pQpp/4P3/p3Npk1/3P1P2/2N3P1/PP4P1/R3KB1R\n"]},{"name":"stdout","output_type":"stream","text":["False 2bk2Q1/1p1p4/r2Bp2p/p1P3N1/4p3/2N5/1PP2PPP/R3KB1R\n"]},{"name":"stdout","output_type":"stream","text":["True r3kb1r/ppp1pppp/5n2/8/2PqP3/P3qPPb/2n2K1P/5B1R\n"]},{"name":"stdout","output_type":"stream","text":["True rnb1k1nr/ppp2ppp/8/P1b1P3/2P4P/4P1P1/1P3K2/R1r2qNR\n"]},{"name":"stdout","output_type":"stream","text":["False 5b2/4nppr/1Q6/pB2N1kp/7P/5Q2/PPPP1PP1/RNB1K2R\n"]},{"name":"stdout","output_type":"stream","text":["True r3kbnr/1p3ppp/p1n5/P2p4/1p6/4Pbq1/2PP4/RNB1KB2\n","False 1r1q1b1r/1pp1p2p/p1npk3/5Qp1/3PP3/4B3/PPP2PPP/RN2K1NR\n","Self-play completed\n","Loaded existing validation data from validation_data.npy\n","\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 5.2426 - policy_output_accuracy: 0.0167 - value_output_mse: 0.0017"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from inf to 5.24257, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 5.2426 - policy_output_accuracy: 0.0167 - value_output_mse: 0.0017   \n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 4.5387 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 0.0013"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from 5.24257 to 4.53872, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 4.5387 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 0.0013   \n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 4.7675 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 0.0012"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss did not improve from 4.53872\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 4.7675 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 0.0012\n"]},{"name":"stdout","output_type":"stream","text":["Iteration 10/7000\n"]},{"name":"stdout","output_type":"stream","text":["False rnbqkbnr/2ppp2P/1p6/p6Q/8/8/PPPP1PPP/RNB1KBNR\n"]},{"name":"stdout","output_type":"stream","text":["True rn2kbnr/ppp2ppp/8/P2p4/1P4b1/6q1/1BPPP2p/1N1QKBNR\n"]},{"name":"stdout","output_type":"stream","text":["True r3kbnr/1pp2ppp/8/1p2pb2/8/P2q1pP1/1PnK1P1P/R1B4R\n"]},{"name":"stdout","output_type":"stream","text":["False 1nb1k1B1/r1pp1Qpr/p7/2P1N1Bp/4P3/2b5/PPP2PPP/RN3RK1\n"]},{"name":"stdout","output_type":"stream","text":["False 2bn3r/rp1p1p2/p1k4n/3NB1Np/3PP3/2QB4/PPP2PPP/R3K2R\n"]},{"name":"stdout","output_type":"stream","text":["True rn2kbnr/ppp2ppp/5q2/3p1K2/8/8/PPPPb1PP/RNBQ1BNR\n"]},{"name":"stdout","output_type":"stream","text":["True r1b1r1k1/1pp2pp1/5n1p/4n2P/P1P1p1P1/4bP1B/4P2R/q3K1N1\n"]},{"name":"stdout","output_type":"stream","text":["False rnb1Q1k1/5p1p/2p1pB2/pp6/3P4/2N2N2/PPP2PPP/R2QKB1R\n"]},{"name":"stdout","output_type":"stream","text":["True r3k2r/pp2np2/2n1b1p1/2p4p/2P1Pb1P/PPp5/1q4P1/K1N2B2\n"]},{"name":"stdout","output_type":"stream","text":["True r1b1r1k1/ppp2ppp/B1nb1n2/3q4/3p1K2/N1B5/P1P2PpP/1R1Q3R\n"]},{"name":"stdout","output_type":"stream","text":["True rn2k2r/ppp2ppp/4p3/3p4/8/2Pn1b1P/PP3q2/RN3K2\n"]},{"name":"stdout","output_type":"stream","text":["False 2Q1k2r/4pp1p/p6b/4P1B1/3P4/2N5/PPP2PPP/R3K1NR\n"]},{"name":"stdout","output_type":"stream","text":["False 1rb1kb1r/p1Np3p/2p3p1/1p2N1B1/3P4/3B4/PPP2PPP/R2Q1RK1\n"]},{"name":"stdout","output_type":"stream","text":["False 2b1k3/3pQ2B/P1p1pP1n/b1P5/7B/P1N2N2/P4PPP/1R2R1K1\n"]},{"name":"stdout","output_type":"stream","text":["True r1b1kb1r/ppp2ppp/2n5/3p4/2q1n1B1/PK1p2P1/1P3P1P/RN6\n","Self-play completed\n","Loaded existing validation data from validation_data.npy\n","\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 5.4146 - policy_output_accuracy: 0.0500 - value_output_mse: 0.0020"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from inf to 5.41459, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 5.4146 - policy_output_accuracy: 0.0500 - value_output_mse: 0.0020   \n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 4.4957 - policy_output_accuracy: 0.1000 - value_output_mse: 0.0010"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from 5.41459 to 4.49567, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 4.4957 - policy_output_accuracy: 0.1000 - value_output_mse: 0.0010   \n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 4.7285 - policy_output_accuracy: 0.0500 - value_output_mse: 0.0012"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss did not improve from 4.49567\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 4.7285 - policy_output_accuracy: 0.0500 - value_output_mse: 0.0012\n"]},{"name":"stdout","output_type":"stream","text":["\n","[After 10 Iterations]\n","Average Policy Output Loss: 0.0\n","Average Value Output Loss: 0.0\n","Iteration 11/7000\n"]},{"name":"stdout","output_type":"stream","text":["False rnbqkb1r/1pppp3/5pQp/p3P3/3P4/8/PPP2PPP/RNB1KBNR\n"]},{"name":"stdout","output_type":"stream","text":["False rn1kQb2/2q1p3/ppp2p1p/3p3Q/3P4/8/PPPN1PPP/R1B1KBNR\n","False 2kq1bn1/1Q3pp1/3r4/pQ2p2p/8/8/PPPP1PPP/RNB1K1NR\n"]},{"name":"stdout","output_type":"stream","text":["False 3q3Q/1p1pNkp1/3B1p2/p3p3/2B1P3/2N5/PPP2PPP/R3K2R\n"]},{"name":"stdout","output_type":"stream","text":["False r1b2N2/p2pp1p1/n1p3Qk/1p6/3PP3/2N4p/PPP2PPP/R3K2R\n"]},{"name":"stdout","output_type":"stream","text":["True r1b1kb1r/2p2p1p/1qn4p/p2p4/1P2P3/P3qN1B/R2K4/1q5R\n"]},{"name":"stdout","output_type":"stream","text":["True r1b1k1nr/ppp2ppp/8/3pp1q1/1b1n4/3P1K2/P1P1PPPP/RNBQ1BNR\n"]},{"name":"stdout","output_type":"stream","text":["True r1b1k2r/ppp3pp/2n5/3npp2/4K2P/5PP1/4P1B1/2Brq1NR\n"]},{"name":"stdout","output_type":"stream","text":["True r1b1kbnr/pp3ppp/2n1p3/2p5/P2q3P/2NPK1P1/RPP3q1/2BQ4\n"]},{"name":"stdout","output_type":"stream","text":["False 1nk3B1/rb2Q3/1Npp1pp1/p3P3/3P4/5N2/PBP2PPP/1R2R1K1\n"]},{"name":"stdout","output_type":"stream","text":["False rnb2b1N/7p/3pk3/p5B1/B2PP1Q1/8/PPP2PPP/RN3RK1\n"]},{"name":"stdout","output_type":"stream","text":["True rnb2rk1/ppp2pp1/7p/b2pp2P/P1P2Pn1/6q1/3PP3/RNBQKBN1\n"]},{"name":"stdout","output_type":"stream","text":["False rnb5/pp6/7R/k5p1/2p5/Q1N5/PPPP1PPP/R1B1KBNR\n"]},{"name":"stdout","output_type":"stream","text":["False 2k4r/3p2pp/B3Np1n/6b1/Np2P3/6B1/PPP2PPP/R2Q1RK1\n"]},{"name":"stdout","output_type":"stream","text":["True rn2k1r1/ppp1n1pp/5p2/7P/P7/1Pbp2P1/2P1bP2/2K4q\n","Self-play completed\n","Loaded existing validation data from validation_data.npy\n","\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 4.6806 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 0.0010"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from inf to 4.68057, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 4.6806 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 0.0010   \n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 5.2854 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 0.0029"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss did not improve from 4.68057\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 5.2854 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 0.0029\n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 4.4751 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 8.4335e-04"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from 4.68057 to 4.47508, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 4.4751 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 8.4335e-04   \n"]},{"name":"stdout","output_type":"stream","text":["Iteration 12/7000\n"]},{"name":"stdout","output_type":"stream","text":["True r2qkb1r/ppp2ppp/5n2/8/2Ppb3/P2K1pP1/1P1P3P/RNBQ3R\n"]},{"name":"stdout","output_type":"stream","text":["True r1b1k2r/ppp2pp1/2n5/3p4/1b2n3/2pBP3/P1P1Kq1P/RNBQ3R\n"]},{"name":"stdout","output_type":"stream","text":["False 1Q2kbr1/p3p1p1/2p1Bp1p/3P4/3P3N/2N5/PPP2PPP/R1B1K2R\n"]},{"name":"stdout","output_type":"stream","text":["False rn1Q4/2kb1N1P/1p1p1p2/p1pB4/1b1P1B2/8/PPP2PPP/RN3RK1\n"]},{"name":"stdout","output_type":"stream","text":["False r1bN2nr/pp1p3p/n2kp3/2bNQ3/2BP4/P7/1PP2PPP/R1B1K2R\n"]},{"name":"stdout","output_type":"stream","text":["False r4k2/5Q2/1B1Npp2/7P/4P1p1/PP6/2PNBPP1/R3K2R\n"]},{"name":"stdout","output_type":"stream","text":["False 1r4Q1/pp2kp2/n5pB/2PN3p/4P3/5N1B/PP3PPP/R4RK1\n"]},{"name":"stdout","output_type":"stream","text":["True r3r1k1/ppp2ppp/5n2/3q4/Pn4P1/5p1b/1bpK1P1P/6R1\n"]},{"name":"stdout","output_type":"stream","text":["True 2r1kbnr/1pp1ppp1/2n5/7p/3Pq3/P6P/4qP2/2B1K2R\n"]},{"name":"stdout","output_type":"stream","text":["True r3kb1r/1p1b1pp1/1p2pn2/n1pp2pP/2P3P1/P4Pq1/R2PP3/1NBQKB2\n"]},{"name":"stdout","output_type":"stream","text":["False rn1q1b1r/ppp2Ppp/1k1p4/1Q3P2/8/8/PPP2PPP/RNB1KBNR\n"]},{"name":"stdout","output_type":"stream","text":["False rnbqkbnr/pp1pp1p1/5pBp/2P1P3/8/8/PPP2PPP/RNBQK1NR\n"]},{"name":"stdout","output_type":"stream","text":["True r1b1kb1r/pp3ppp/8/2Pp4/1Knnp1P1/Pq6/1P2P2P/RN3BNR\n"]},{"name":"stdout","output_type":"stream","text":["False 1n3b1r/3P1kpp/1p6/p1pQ2B1/4B3/8/PPP2PPP/RN2K2R\n"]},{"name":"stdout","output_type":"stream","text":["False 1rbq3r/1ppp1Q1p/p1n4k/6pB/3PP1N1/8/PP3PPP/RNB2RK1\n","Self-play completed\n","Loaded existing validation data from validation_data.npy\n","\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 4.2760 - policy_output_accuracy: 0.0333 - value_output_mse: 0.0010"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from inf to 4.27601, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 4.2760 - policy_output_accuracy: 0.0333 - value_output_mse: 0.0010   \n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 4.7034 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 0.0011"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss did not improve from 4.27601\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 4.7034 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 0.0011\n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 4.7152 - policy_output_accuracy: 0.0333 - value_output_mse: 0.0011"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss did not improve from 4.27601\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 4.7152 - policy_output_accuracy: 0.0333 - value_output_mse: 0.0011\n"]},{"name":"stdout","output_type":"stream","text":["Iteration 13/7000\n"]},{"name":"stdout","output_type":"stream","text":["True r3k1nr/pppb1ppp/2n1p3/3p1PP1/7q/3P3P/PPPNPb2/R2QKB1R\n"]},{"name":"stdout","output_type":"stream","text":["False 3Qkbr1/p4p1p/2p3p1/1p4B1/4P1b1/5N2/PPP1BPPP/RN3RK1\n"]},{"name":"stdout","output_type":"stream","text":["True r3kb2/pppb1ppr/2n5/3p4/3P4/NP2P1n1/P1P2qBR/R1B4K\n"]},{"name":"stdout","output_type":"stream","text":["True 2kr1b1r/ppp2ppp/2n5/3pp3/P3P3/RPPb1P2/1BKP1n2/1N4q1\n"]},{"name":"stdout","output_type":"stream","text":["False rn1qkbn1/2ppp1pr/p4pB1/1P1P3p/3P4/8/1PPN1PPP/R1BQK1NR\n"]},{"name":"stdout","output_type":"stream","text":["True r3k3/pp1n1pp1/4b3/1pbpn3/2P4q/4Pp2/PP4K1/R4BR1\n"]},{"name":"stdout","output_type":"stream","text":["True r1bq1rk1/pp3ppp/2n1p2n/2pp4/3P3P/PPP3b1/3NP1P1/R1BQKBNR\n"]},{"name":"stdout","output_type":"stream","text":["True rn2kb1r/ppp2ppp/8/3nP1N1/2p5/P1K5/bP2PPPP/2Bq1B1R\n"]},{"name":"stdout","output_type":"stream","text":["True rnb1kbnr/pppp1ppp/8/1P6/7q/P7/2PPP1pP/RNBQKBNR\n"]},{"name":"stdout","output_type":"stream","text":["True rnb1kbnr/ppp2ppp/8/3p4/3P3P/P1P1p3/RPQ1P1P1/1N1K1qNR\n"]},{"name":"stdout","output_type":"stream","text":["True r3k2r/pppb1ppp/2n2n2/3K4/1b2p2P/1Pq1PN2/P4PP1/R1B2B1R\n"]},{"name":"stdout","output_type":"stream","text":["True 3q3r/1p1k1pp1/1p2bn1p/r1pp4/1KPn4/6P1/3N1PRP/b1B2B2\n"]},{"name":"stdout","output_type":"stream","text":["False r2k1r2/2pQpp1p/7b/p2P2p1/3P4/2N2N1B/PPP2PPP/R4RK1\n"]},{"name":"stdout","output_type":"stream","text":["False r1b5/2pp2Qk/pP2p1pB/4Np1p/P1N4P/3B1P2/1PPQ2P1/R3K2R\n"]},{"name":"stdout","output_type":"stream","text":["False r1n2b1R/1bpR1p2/2n1kN2/p3P1p1/2B1P3/2P1BN2/PP2Q1P1/2K5\n","Self-play completed\n","Loaded existing validation data from validation_data.npy\n","\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 4.7285 - policy_output_accuracy: 0.0833 - value_output_mse: 9.2188e-04"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from inf to 4.72855, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 4.7285 - policy_output_accuracy: 0.0833 - value_output_mse: 9.2188e-04   \n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 5.1698 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 0.0017"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss did not improve from 4.72855\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 5.1698 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 0.0017\n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 4.3986 - policy_output_accuracy: 0.0167 - value_output_mse: 0.0015"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from 4.72855 to 4.39864, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 4.3986 - policy_output_accuracy: 0.0167 - value_output_mse: 0.0015   \n"]},{"name":"stdout","output_type":"stream","text":["Iteration 14/7000\n"]},{"name":"stdout","output_type":"stream","text":["False r2qk1nr/p1ppp1Pp/n6b/7Q/8/8/PPPP1PPP/RNB1K1NR\n"]},{"name":"stdout","output_type":"stream","text":["True r3k1nr/pppb1ppp/2n1q3/3K4/Pb3p2/2NP3P/1PP1P1P1/R3QB1R\n"]},{"name":"stdout","output_type":"stream","text":["True 1r2kbnr/pp3ppp/2n5/3p4/P2pb3/2PK2PP/1q3PR1/RN3BN1\n"]},{"name":"stdout","output_type":"stream","text":["False 3r1b1r/2pPkQp1/p2p4/1p4Np/1P1P2B1/2P1B3/1P1K1PPP/RN5R\n"]},{"name":"stdout","output_type":"stream","text":["False 4Bbr1/r1p2kpp/3p1p1n/8/p7/2N2N2/PPP1QPPP/R1B2RK1\n"]},{"name":"stdout","output_type":"stream","text":["True rn2kbnr/ppp2ppp/4b3/1P2p3/P7/2pP1PqP/2P1P3/R1BQKB2\n"]},{"name":"stdout","output_type":"stream","text":["True r3k2r/pp3ppp/2n5/3np2P/1b1p4/4pP2/P1P1Pq2/R4K2\n"]},{"name":"stdout","output_type":"stream","text":["True rnb1kbnr/pppp1ppp/8/4p3/6Pq/5P2/PPPPP2P/RNBQKBNR\n"]},{"name":"stdout","output_type":"stream","text":["True r3kb1r/ppp2ppp/2n5/P2ppP1b/3P2n1/NP2PKP1/R1P4P/5qNR\n"]},{"name":"stdout","output_type":"stream","text":["False rnb2k2/p4Q1p/3ppB2/1pp3N1/3PP3/P2B4/1PP2PPP/RN2K2R\n"]},{"name":"stdout","output_type":"stream","text":["True r2q1rk1/ppp2ppp/8/4p3/2Pnn1bP/6P1/P1QP1b2/RNBK3R\n"]},{"name":"stdout","output_type":"stream","text":["False Q4bnr/2p1q3/pN2kp1p/3Qp1p1/4P3/5N1b/1PP2PPP/R1B1KB1R\n"]},{"name":"stdout","output_type":"stream","text":["False 1k3b2/pQ4pr/B2ppp2/2p3Np/8/P3B3/1PPN1PPP/R3K2R\n"]},{"name":"stdout","output_type":"stream","text":["True r1b1k2r/pp3pp1/4p2p/3p2P1/2PnnP2/1P2b2N/P2q3P/R2K1BR1\n"]},{"name":"stdout","output_type":"stream","text":["False r2kQbnr/5Bp1/p1nP1p1p/1pP1P3/8/2N1BN2/PPP3PP/R3K2R\n","Self-play completed\n","Loaded existing validation data from validation_data.npy\n","\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 4.6104 - policy_output_accuracy: 0.0167 - value_output_mse: 9.0051e-04"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from inf to 4.61045, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 4.6104 - policy_output_accuracy: 0.0167 - value_output_mse: 9.0051e-04   \n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 4.8890 - policy_output_accuracy: 0.0500 - value_output_mse: 8.9761e-04"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss did not improve from 4.61045\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 4.8890 - policy_output_accuracy: 0.0500 - value_output_mse: 8.9761e-04\n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 5.4749 - policy_output_accuracy: 0.0167 - value_output_mse: 0.0012"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss did not improve from 4.61045\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 5.4749 - policy_output_accuracy: 0.0167 - value_output_mse: 0.0012\n"]},{"name":"stdout","output_type":"stream","text":["Iteration 15/7000\n"]},{"name":"stdout","output_type":"stream","text":["True r3kbnr/ppp2ppp/2n5/3pp3/5Pbq/1PN5/PBPPP2P/R2QKBNR\n"]},{"name":"stdout","output_type":"stream","text":["False rnbqkbnr/p3p3/1p3p1p/3pN2Q/2BPP3/8/PPP2PPP/RNB1K2R\n"]},{"name":"stdout","output_type":"stream","text":["True rnb1k1nr/ppp2ppp/8/3pp3/1b4Pq/N4P2/P1PPP2P/R1BQKBNR\n"]},{"name":"stdout","output_type":"stream","text":["True rn2k2r/pppbqppp/8/8/1b2n2P/N4K2/P1P2qP1/R1B3NR\n"]},{"name":"stdout","output_type":"stream","text":["True r1b1rnk1/ppp2pp1/5n1p/8/4Pb1P/P1P3PR/1P1q1P2/r1B1KB2\n"]},{"name":"stdout","output_type":"stream","text":["False 3Q1N1r/2P1kppp/4p3/pp6/3P4/8/PPP2PPP/RNB1K2R\n"]},{"name":"stdout","output_type":"stream","text":["True r3kbn1/ppp2ppr/8/2Pp4/5p2/3nP3/PP1P1q1P/RNB2K1R\n"]},{"name":"stdout","output_type":"stream","text":["False 1n5r/rp2Q1kp/5ppb/pNp5/P1B5/5N2/1PPP1PPP/R1B1K2R\n"]},{"name":"stdout","output_type":"stream","text":["True r3kbnr/pp4pp/2n2p2/4p2b/8/PPKPP3/5P1P/RNq5\n"]},{"name":"stdout","output_type":"stream","text":["False r1bq1b1r/2Nkppp1/1pP4p/pBp5/3P1Bn1/5N2/PPP2PPP/R2QK2R\n"]},{"name":"stdout","output_type":"stream","text":["True r2k3r/p4pb1/p1n2np1/1Pp4p/6bP/P1Pp1N2/RBq2PP1/1NK4R\n"]},{"name":"stdout","output_type":"stream","text":["True rnbqk2r/ppp2ppp/8/1P2p3/5Pn1/P1P5/3NPbPP/R1BQKBR1\n","False r2k1bqr/pp1Q3p/B3PppB/2P5/4P3/2N2N2/PP3PPP/R4RK1\n"]},{"name":"stdout","output_type":"stream","text":["False rnbqk3/1pp2Q2/p2P4/3PNpp1/4N3/3B4/PPP2PPP/R1B1R1K1\n"]},{"name":"stdout","output_type":"stream","text":["True r1b1k2r/1pp1npp1/8/p2pp3/1n6/2K1PP1p/2q5/8\n","Self-play completed\n","Loaded existing validation data from validation_data.npy\n","\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 4.4775 - policy_output_accuracy: 0.0833 - value_output_mse: 8.4107e-04"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from inf to 4.47747, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 4.4775 - policy_output_accuracy: 0.0833 - value_output_mse: 8.4107e-04   \n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 4.7788 - policy_output_accuracy: 0.1333 - value_output_mse: 0.0011"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss did not improve from 4.47747\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 4.7788 - policy_output_accuracy: 0.1333 - value_output_mse: 0.0011\n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 4.4598 - policy_output_accuracy: 0.0500 - value_output_mse: 0.0010"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from 4.47747 to 4.45982, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 4.4598 - policy_output_accuracy: 0.0500 - value_output_mse: 0.0010   \n"]},{"name":"stdout","output_type":"stream","text":["\n","[After 15 Iterations]\n","Average Policy Output Loss: 0.0\n","Average Value Output Loss: 0.0\n","Iteration 16/7000\n"]},{"name":"stdout","output_type":"stream","text":["False rnbqkbn1/1ppppB2/8/p4p1Q/3PP3/8/PPP2PPP/RNB1K1NR\n"]},{"name":"stdout","output_type":"stream","text":["False Rnb2bnr/4pppp/2k5/1NPQ4/2B5/8/1PP2PPP/2B1K1NR\n"]},{"name":"stdout","output_type":"stream","text":["False r1bq1br1/pp1pkQ2/2p2p1p/4P1p1/2B1P3/2N1B3/PPP2PPP/R3K1NR\n"]},{"name":"stdout","output_type":"stream","text":["False 1r2kbnr/pp5p/n7/1bp1NPBQ/8/2N5/PPP2PPP/R3K2R\n"]},{"name":"stdout","output_type":"stream","text":["True rnb1kbnr/pppp1ppp/8/4p3/5P2/6qP/PPPPP3/RNBQKBNR\n"]},{"name":"stdout","output_type":"stream","text":["True rn2kbnr/pbp2ppp/8/4p3/p2p2Pq/P4P2/1PPPP2P/R1BQKBNR\n"]},{"name":"stdout","output_type":"stream","text":["False 1q4r1/n1pp3p/Bp1k1Q2/3Np3/3PP2P/8/PPPN1PP1/R3K2R\n"]},{"name":"stdout","output_type":"stream","text":["True rn1qk2r/ppp2ppp/4b3/P7/4Pp2/2bP1P2/2q1K1PP/5BR1\n"]},{"name":"stdout","output_type":"stream","text":["False 2R5/rp1Q3p/2p5/6p1/p2Pk3/2N5/PPP2PPP/R1B1KBNR\n"]},{"name":"stdout","output_type":"stream","text":["True rn2kbnr/ppp2ppp/8/3pp3/6Pq/1P3P1b/P1PPP2P/RNBQKB1R\n"]},{"name":"stdout","output_type":"stream","text":["True 1r3b1r/p2k1pp1/p1n1b1n1/2pp4/3P4/1PP1Pp2/P4P2/RNB2K1q\n"]},{"name":"stdout","output_type":"stream","text":["True r1b1k2r/pppp1ppp/2n5/7n/Pb1p4/1P3PqP/3NP3/R1BQKBNR\n"]},{"name":"stdout","output_type":"stream","text":["True rnb1r1k1/1pp2p1p/7p/p6P/P3n1P1/1P1PPp2/2P5/q2K1B1R\n"]},{"name":"stdout","output_type":"stream","text":["False rkb2bnr/pp2Ppp1/8/2P1Q2p/4P3/2N2N2/1PP1BPPP/R1B1K2R\n"]},{"name":"stdout","output_type":"stream","text":["False rnbk4/3pB1p1/p2Pp1B1/1pp1Pp1p/8/2N2N2/PPP2PPP/R2Q1RK1\n","Self-play completed\n","Loaded existing validation data from validation_data.npy\n","\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 4.3787 - policy_output_accuracy: 0.0167 - value_output_mse: 8.9284e-04"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from inf to 4.37872, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 4.3787 - policy_output_accuracy: 0.0167 - value_output_mse: 8.9284e-04   \n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 5.0266 - policy_output_accuracy: 0.0167 - value_output_mse: 8.1613e-04"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss did not improve from 4.37872\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 5.0266 - policy_output_accuracy: 0.0167 - value_output_mse: 8.1613e-04\n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 4.6422 - policy_output_accuracy: 0.0500 - value_output_mse: 8.0319e-04"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss did not improve from 4.37872\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 4.6422 - policy_output_accuracy: 0.0500 - value_output_mse: 8.0319e-04\n"]},{"name":"stdout","output_type":"stream","text":["Iteration 17/7000\n"]},{"name":"stdout","output_type":"stream","text":["False r1bk3r/p1ppQp1p/8/1B4B1/3P4/8/PPP2PPP/RN2K1NR\n"]},{"name":"stdout","output_type":"stream","text":["False 2bk1Q2/2ppNB2/rpn4p/p2n2N1/4P3/8/PPP2PPP/R1B2RK1\n"]},{"name":"stdout","output_type":"stream","text":["True r1b1kbnr/pppp2pp/2n5/5p2/P1PP4/4PP1P/RP6/1NKq2q1\n"]},{"name":"stdout","output_type":"stream","text":["False rn3b2/pp5p/4Q3/2p2pB1/2Bk4/5N2/PP3PPP/R3K2R\n"]},{"name":"stdout","output_type":"stream","text":["True rn2k2r/1pp2pp1/3bbn2/p2p4/8/PPPPp1qp/3RP3/1N1QKB1R\n"]},{"name":"stdout","output_type":"stream","text":["False rn1R1b1r/ppp2p2/8/3Q2pp/3k4/8/PPPP1PPP/RNB1KBNR\n"]},{"name":"stdout","output_type":"stream","text":["False r1bq1b1r/pppP2pp/5n2/4Q3/3PkB2/8/PPP2PPP/RN2KBNR\n"]},{"name":"stdout","output_type":"stream","text":["True rn2kbnr/ppp2ppp/8/4p3/P1Pq2bP/1PK5/3P1P2/RNB1n3\n"]},{"name":"stdout","output_type":"stream","text":["True rnb1kbnr/ppp3pp/4p3/3p4/1P3pPq/N7/P1PPP2P/R1BQKB1R\n"]},{"name":"stdout","output_type":"stream","text":["False 2Q1kbnr/pp4p1/7p/3NNp2/3P4/8/PPP2PPP/R1BQKB1R\n"]},{"name":"stdout","output_type":"stream","text":["True rnb1kbnr/pppp1ppp/8/8/2P4q/NP6/P2PP1pP/R1BQKBNR\n"]},{"name":"stdout","output_type":"stream","text":["False 1nQ2b2/2kp1pr1/3N2p1/1BP4p/p3P3/5N2/PPP2PPP/R3K2R\n"]},{"name":"stdout","output_type":"stream","text":["False rnb2b1r/p2q1ppp/2Ppp2n/kQ6/B2PP3/2N2N2/P1P2PPP/1RB2RK1\n"]},{"name":"stdout","output_type":"stream","text":["True rn1r4/ppp1kppp/5n2/2b1p2P/P1P3b1/1P2K1PN/4PP2/5B1R\n"]},{"name":"stdout","output_type":"stream","text":["True r3k2r/1pp2pp1/2n1bn1p/8/5bP1/PqPP1p2/p1K1Bp1P/3QR3\n","Self-play completed\n","Loaded existing validation data from validation_data.npy\n","\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 4.6953 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 0.0015"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from inf to 4.69529, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 4.6953 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 0.0015   \n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 4.5241 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 9.2947e-04"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from 4.69529 to 4.52409, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 4.5241 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 9.2947e-04   \n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 4.5178 - policy_output_accuracy: 0.0333 - value_output_mse: 8.0611e-04"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from 4.52409 to 4.51783, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 4.5178 - policy_output_accuracy: 0.0333 - value_output_mse: 8.0611e-04   \n"]},{"name":"stdout","output_type":"stream","text":["Iteration 18/7000\n"]},{"name":"stdout","output_type":"stream","text":["True rn2kb1r/ppp2ppp/4b3/3p1n2/PP1p4/B4PqP/2P1P1K1/RN1Q1BNR\n"]},{"name":"stdout","output_type":"stream","text":["False 1n1q1br1/rpp1p1p1/3k3p/p2QN3/2BP4/2N1B3/PPP2PPP/R3K2R\n"]},{"name":"stdout","output_type":"stream","text":["True r3k2r/ppp2pp1/8/2bp4/4p1p1/PP1nP3/2bP1qKP/RN4NR\n"]},{"name":"stdout","output_type":"stream","text":["False Bn1Qkbn1/8/pp2Pp1r/2P3pp/2P5/2N1B2P/PP3P1P/2KR2NR\n"]},{"name":"stdout","output_type":"stream","text":["True rn2k2r/ppp2ppp/7n/3Pp3/P1P2q2/3PK3/7P/1N1b1BNR\n"]},{"name":"stdout","output_type":"stream","text":["True 2kr3r/ppp2ppp/2nn4/3bpP1P/3p2P1/8/PB4q1/4b1K1\n"]},{"name":"stdout","output_type":"stream","text":["False r1b1k1r1/1p2Q1pp/pP2p3/3P1pBn/8/2P4N/PP3PPP/RN2K2R\n"]},{"name":"stdout","output_type":"stream","text":["True r2qk2r/1pp1nppp/p1nb4/Q2p4/3P4/N1PKPP2/P4q2/R1B2b2\n"]},{"name":"stdout","output_type":"stream","text":["False r1bk1r2/pp1p1Pp1/n2P4/2p3B1/7p/5N2/PPPKQPPP/RN3B1R\n"]},{"name":"stdout","output_type":"stream","text":["False 3Q2nr/pp6/2p4p/2k1p3/1P6/2PB4/P2P1PPP/RNB1K2R\n"]},{"name":"stdout","output_type":"stream","text":["False r1bqkbnr/ppppp3/2n3Q1/8/8/8/PPPP1PPP/RNB1KBNR\n"]},{"name":"stdout","output_type":"stream","text":["False rnb2b1r/pp1p1Np1/2kP2Bp/3Q4/N3PB2/8/PPP2PPP/R3K2R\n"]},{"name":"stdout","output_type":"stream","text":["True r3kb1r/pp4pp/2n1b3/5p2/2p1K3/P7/1PPP1q1P/RNBQ1B1R\n"]},{"name":"stdout","output_type":"stream","text":["True rn2k2r/pp2n1pp/2p5/P4p2/2BPK3/2P3q1/5p2/R1B5\n"]},{"name":"stdout","output_type":"stream","text":["True r3k2r/1p1n1p1p/2n1b2p/3pp3/P1p5/b2q1PP1/7P/2K3NR\n","Self-play completed\n","Loaded existing validation data from validation_data.npy\n","\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 4.0665 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 8.1704e-04"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from inf to 4.06655, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 4.0665 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 8.1704e-04   \n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 4.0311 - policy_output_accuracy: 0.0167 - value_output_mse: 8.0889e-04"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from 4.06655 to 4.03110, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 4.0311 - policy_output_accuracy: 0.0167 - value_output_mse: 8.0889e-04   \n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 3.7892 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 9.5987e-04"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from 4.03110 to 3.78919, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 3.7892 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 9.5987e-04   \n"]},{"name":"stdout","output_type":"stream","text":["Iteration 19/7000\n"]},{"name":"stdout","output_type":"stream","text":["False rnQ1kb1r/pp5p/3P4/2p1Nnp1/2B1P3/8/PPP2PPP/RNB1K2R\n"]},{"name":"stdout","output_type":"stream","text":["False rnbk3r/p1pp3P/5B2/1B2Q3/3P4/8/PPP2PPP/RN2K1NR\n"]},{"name":"stdout","output_type":"stream","text":["True r3k2r/p3pp1p/2np1npb/2p5/pqP1P1b1/N2P4/PP3P1P/R3KBNR\n"]},{"name":"stdout","output_type":"stream","text":["False rnq3k1/p2p1pQ1/4p2B/2pP4/2B1N3/8/PPP1NPP1/R3K2R\n"]},{"name":"stdout","output_type":"stream","text":["True r2nk2r/1ppbqppp/3b1n2/pP6/2P3PP/PQ1P4/2K3r1/R3q3\n"]},{"name":"stdout","output_type":"stream","text":["False r1b3Q1/1p1pkp2/p2Q3p/n1p5/4PB2/b1N5/PPP2PPP/R3KBNR\n"]},{"name":"stdout","output_type":"stream","text":["True rnb1k1nr/pppp1ppp/6q1/b7/8/P3P2P/1Kq5/RNB3NR\n"]},{"name":"stdout","output_type":"stream","text":["False 2Q1k3/p5p1/2pP1p1r/2p3Pp/2B1p3/2N2N2/PPP2PP1/R3K2R\n"]},{"name":"stdout","output_type":"stream","text":["False r1bqkbnr/ppppp3/6Qp/4Np2/1n1PP3/8/PPP2PPP/RNB1KB1R\n"]},{"name":"stdout","output_type":"stream","text":["True r3kbnr/pp3ppp/8/1p2B1q1/nPb5/PK1p4/R4PPP/1N1Q2NR\n"]},{"name":"stdout","output_type":"stream","text":["True rnb1kbnr/pp3ppp/8/1p1pp3/1P3PPq/8/P1PPP2P/R1BQKBNR\n"]},{"name":"stdout","output_type":"stream","text":["False 7Q/5p2/3B1k2/p2P4/3P3p/1P1B1N1P/3N1PP1/R3K2R\n"]},{"name":"stdout","output_type":"stream","text":["False r3kr2/p1BnQp1p/3p4/1B1Np3/3PP3/5N2/PPP2PPP/R3K2R\n"]},{"name":"stdout","output_type":"stream","text":["False 1r1q1b1r/1pp2Npp/3k4/pB3p2/3P4/2N5/PPP2PPP/R1BQR1K1\n"]},{"name":"stdout","output_type":"stream","text":["True r2q1k2/p1p2ppp/2p2n1b/P2p4/1q1K1P2/1P1P2P1/4r1b1/8\n","Self-play completed\n","Loaded existing validation data from validation_data.npy\n","\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 3.5978 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 0.0011"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from inf to 3.59785, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 3.5978 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 0.0011   \n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 4.0603 - policy_output_accuracy: 0.0167 - value_output_mse: 0.0017"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss did not improve from 3.59785\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 4.0603 - policy_output_accuracy: 0.0167 - value_output_mse: 0.0017\n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 4.3378 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 9.6248e-04"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss did not improve from 3.59785\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 4.3378 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 9.6248e-04\n"]},{"name":"stdout","output_type":"stream","text":["Iteration 20/7000\n"]},{"name":"stdout","output_type":"stream","text":["True rnb1kbnr/ppp2ppp/8/3pp3/5PPq/2P5/PP1PP2P/RNBQKBNR\n"]},{"name":"stdout","output_type":"stream","text":["True r1bqkbnr/pp3ppp/4p3/2pp3P/8/5nP1/PPPPNP2/RNBQKB1R\n"]},{"name":"stdout","output_type":"stream","text":["True r3r1k1/ppp2ppp/5n2/3q1b2/2Kn3P/4pPP1/P2b4/R2Q1B1R\n","True r3k2r/ppp2ppp/8/n7/qbp5/4P2P/1K1P2P1/1NBn1BNR\n"]},{"name":"stdout","output_type":"stream","text":["False 2Q2b2/p2k1p1r/B2p1P2/2P1p2p/6P1/8/PPP2PP1/RNB1K1NR\n"]},{"name":"stdout","output_type":"stream","text":["False rnb4R/1pp2pp1/3p3p/p1k5/4Q3/3BB3/PPP2PPP/RN2K1NR\n"]},{"name":"stdout","output_type":"stream","text":["True rnb1kbnr/pppp1ppp/8/4p3/5P2/6qP/PPPPP3/RNBQKBNR\n"]},{"name":"stdout","output_type":"stream","text":["True r1b1k2r/1p2bppp/B1n1p3/8/4p1P1/2n4P/4KP2/2q3NR\n"]},{"name":"stdout","output_type":"stream","text":["True rn1qkbnr/ppp2ppp/3p4/8/8/P1P1PP1b/RPQP4/1NB1Kq2\n"]},{"name":"stdout","output_type":"stream","text":["True rn2kbnr/ppp2p2/6pp/3p3K/6P1/1PP5/P2Pbq1P/RNBQ1BNR\n"]},{"name":"stdout","output_type":"stream","text":["True r3k2r/pp2bppp/n7/1Np5/2p3bP/P1KqP3/1P2pPP1/1RB1n2R\n"]},{"name":"stdout","output_type":"stream","text":["False r4brk/4pN2/p3N2p/1pp2B1n/7B/3P2P1/PPP1KP1P/R2Q3R\n"]},{"name":"stdout","output_type":"stream","text":["True r4r1k/2p2ppp/2n2b2/1p6/Np1n1p2/1RBPqPPb/P3B2P/6KR\n"]},{"name":"stdout","output_type":"stream","text":["True r3k2r/ppp2ppp/2n5/3qp3/Pb4P1/3p3P/1K2b3/RNBn4\n"]},{"name":"stdout","output_type":"stream","text":["False r1bqkb1r/p1p1nB1p/1p3p2/2n1N3/3PP3/8/PPP2PPP/R1BQK2R\n","Self-play completed\n","Loaded existing validation data from validation_data.npy\n","\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 3.8425 - policy_output_accuracy: 0.2000 - value_output_mse: 8.1267e-04"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from inf to 3.84248, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 3.8425 - policy_output_accuracy: 0.2000 - value_output_mse: 8.1267e-04   \n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 3.7313 - policy_output_accuracy: 0.0667 - value_output_mse: 7.9116e-04"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from 3.84248 to 3.73129, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 3.7313 - policy_output_accuracy: 0.0667 - value_output_mse: 7.9116e-04   \n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 3.8239 - policy_output_accuracy: 0.1333 - value_output_mse: 8.0096e-04"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss did not improve from 3.73129\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 3.8239 - policy_output_accuracy: 0.1333 - value_output_mse: 8.0096e-04\n"]},{"name":"stdout","output_type":"stream","text":["\n","[After 20 Iterations]\n","Average Policy Output Loss: 0.0\n","Average Value Output Loss: 0.0\n","Iteration 21/7000\n"]},{"name":"stdout","output_type":"stream","text":["False rnbqkb1r/pp1pp2p/2p5/5pBQ/3PP3/2N5/PPP2PPP/R3KBNR\n"]},{"name":"stdout","output_type":"stream","text":["False rnbq1b1r/1ppp2pp/p2P1pkn/4p3/2B1P2N/8/PPP2PPP/RNBQ1RK1\n"]},{"name":"stdout","output_type":"stream","text":["False q3kb1r/B1pQ1p2/2P1P3/p4n1p/B5b1/2N2N2/PPP2PPP/R3K2R\n"]},{"name":"stdout","output_type":"stream","text":["False rn6/p1k3pp/B2Q4/q1NpP3/8/8/PPPP1PPP/RNB1K2R\n"]},{"name":"stdout","output_type":"stream","text":["True 4k1nr/rp2pp1p/2n3p1/P7/1p6/2P2b2/3Pq2P/bNB1K2R\n"]},{"name":"stdout","output_type":"stream","text":["False N1b3r1/1p1kn2p/p3p3/1BP2pB1/7R/5NP1/PPP1KPP1/3R2Q1\n"]},{"name":"stdout","output_type":"stream","text":["True rn2kbnr/pp3ppp/2p5/4p3/1P6/6Pb/P2PPP1P/RNBQK1q1\n"]},{"name":"stdout","output_type":"stream","text":["True rn2k2r/ppp1bppp/5n2/5bB1/2Pp4/P2K2P1/RP3q1P/1NQ5\n"]},{"name":"stdout","output_type":"stream","text":["False r1b2knr/pp1n1Q1p/3Ppp2/1B2N1P1/4P3/2P5/PP3PP1/R1B1K2R\n"]},{"name":"stdout","output_type":"stream","text":["True 2k4r/ppp3pp/4b3/4pp2/1PPnPPnP/7N/P3K1P1/2qr1B2\n"]},{"name":"stdout","output_type":"stream","text":["True r3kb1r/ppp2ppp/2n5/4p3/PP2n3/2Pp3b/4PP1P/1RBQK1q1\n"]},{"name":"stdout","output_type":"stream","text":["True r3k2r/ppp2ppp/2nb4/5q1K/P2p3P/1P3p1R/2PPP3/3Q2N1\n"]},{"name":"stdout","output_type":"stream","text":["True rn2k1nr/pp1b3p/5pp1/7K/3pp1P1/7B/P4q1P/R1B4R\n"]},{"name":"stdout","output_type":"stream","text":["True 4k2r/ppp2ppp/4p3/2n3P1/Pb6/1bn4P/1K1rn3/R7\n"]},{"name":"stdout","output_type":"stream","text":["False rnN2b1r/1p2p1pp/2p2n2/p1kp1P1Q/3P4/2P5/PP2BPPP/RNB1K2R\n","Self-play completed\n","Loaded existing validation data from validation_data.npy\n","\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 3.9177 - policy_output_accuracy: 0.1167 - value_output_mse: 9.6670e-04"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from inf to 3.91770, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 3.9177 - policy_output_accuracy: 0.1167 - value_output_mse: 9.6670e-04   \n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 3.8016 - policy_output_accuracy: 0.1333 - value_output_mse: 8.9087e-04"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from 3.91770 to 3.80165, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 3.8016 - policy_output_accuracy: 0.1333 - value_output_mse: 8.9087e-04   \n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 4.5351 - policy_output_accuracy: 0.0667 - value_output_mse: 0.0015"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss did not improve from 3.80165\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 4.5351 - policy_output_accuracy: 0.0667 - value_output_mse: 0.0015\n"]},{"name":"stdout","output_type":"stream","text":["Iteration 22/7000\n"]},{"name":"stdout","output_type":"stream","text":["True rnb1k1nr/ppp2ppp/8/3pp2P/8/2P2Pq1/PP1PP3/RNBQKBN1\n"]},{"name":"stdout","output_type":"stream","text":["False 5bnr/p4Q1p/2B1p2k/6pQ/8/8/PPPP1PPP/RNB1K1NR\n"]},{"name":"stdout","output_type":"stream","text":["True r1b1k1nr/pp2pp1p/3p4/2p4p/P2nP3/3P2P1/4KP1P/2q2BNR\n"]},{"name":"stdout","output_type":"stream","text":["False r7/kpQ1p3/p3N3/1Npq1p2/1P2P3/3PB3/1PP2PPP/R3KB1R\n"]},{"name":"stdout","output_type":"stream","text":["True 5rk1/1ppb1ppp/r7/3pp3/P2n1Pn1/2pP2q1/4P3/2RQKB2\n"]},{"name":"stdout","output_type":"stream","text":["False r1b1Q1kr/p2p1ppp/n1p2P2/5P2/8/3B1N1P/PPP2PP1/RNB1K2R\n"]},{"name":"stdout","output_type":"stream","text":["False r1bqkb1N/p2ppQ1p/n7/1Bp5/3P4/8/PPP2PPP/RNB1K1NR\n"]},{"name":"stdout","output_type":"stream","text":["False rk2b3/p1Q5/1p1P4/6N1/4p3/2N4P/PPPB1PP1/R3K2R\n"]},{"name":"stdout","output_type":"stream","text":["True r3kbnr/ppp2ppp/8/4p3/1npP1P2/2K1P2N/PPq3P1/RNB2b1R\n"]},{"name":"stdout","output_type":"stream","text":["False rn1Q1k1r/1pB1npbp/4b3/pB2P3/4P3/7N/PPP2PPP/RN2K2R\n"]},{"name":"stdout","output_type":"stream","text":["False rn1Q4/3k1p1p/p1p5/1p1Pp1B1/1q1P4/2N5/PP3PPP/R3KBNR\n"]},{"name":"stdout","output_type":"stream","text":["False 4k3/2Np1p1N/B4B2/p7/4P2p/1P3P2/1PP3PP/R3R1K1\n"]},{"name":"stdout","output_type":"stream","text":["True r1b1kb1r/ppp2ppp/2n2n2/8/5p2/PPqPqP2/5KPP/3Q1B1R\n"]},{"name":"stdout","output_type":"stream","text":["True rn2kbnr/pp3pp1/8/2pp4/1PPpb3/3K4/P4q2/RNB5\n"]},{"name":"stdout","output_type":"stream","text":["True 5rk1/p1pn2pp/3pb3/br2p1p1/2pnP1PP/P7/RK1P4/5q2\n","Self-play completed\n","Loaded existing validation data from validation_data.npy\n","\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 3.4217 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 7.2191e-04"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from inf to 3.42172, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 3.4217 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 7.2191e-04   \n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 3.5750 - policy_output_accuracy: 0.0667 - value_output_mse: 0.0014"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss did not improve from 3.42172\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 3.5750 - policy_output_accuracy: 0.0667 - value_output_mse: 0.0014\n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 3.2606 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 6.5761e-04"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from 3.42172 to 3.26057, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 3.2606 - policy_output_accuracy: 0.0000e+00 - value_output_mse: 6.5761e-04   \n"]},{"name":"stdout","output_type":"stream","text":["Iteration 23/7000\n"]},{"name":"stdout","output_type":"stream","text":["False rnR2b1r/2p2p1p/p4kp1/1p1pQ3/3P4/8/PPP2PPP/RNB1KBNR\n"]},{"name":"stdout","output_type":"stream","text":["False rnbq2nQ/ppppp1b1/4k3/3P3Q/4N3/8/PPP2PPP/R1B1KBNR\n"]},{"name":"stdout","output_type":"stream","text":["True rnb1k2r/1pp2ppp/p3p3/1P2p2q/1b2nP2/7K/P1P3PP/R1B3NR\n"]},{"name":"stdout","output_type":"stream","text":["False 1nbq2r1/3p2pN/3Nk2n/2pQPpB1/p3P3/8/PPP1BPPP/R4RK1\n"]},{"name":"stdout","output_type":"stream","text":["True r3rbk1/pp3ppp/5n2/4p3/3qp1bP/Q2nK3/P2B1PP1/RN4NR\n"]},{"name":"stdout","output_type":"stream","text":["False r2qkb1r/pb1ppQ1p/2n2n2/1Bp3N1/3PP3/2N5/PPP2PPP/R1B1K2R\n"]},{"name":"stdout","output_type":"stream","text":["False 2Qqkb1r/3Bpppp/8/p1p1P3/8/5P2/PPP3PP/RNB1K1NR\n"]},{"name":"stdout","output_type":"stream","text":["True r1b1k1nr/ppp2ppp/8/3p4/6Pn/5qb1/P1PP4/RNB1KB1R\n"]},{"name":"stdout","output_type":"stream","text":["False rnbQkbr1/2P1pp2/p7/1p3Ppp/8/5N2/PPP2PPP/R1B1KB1R\n"]},{"name":"stdout","output_type":"stream","text":["True rnb1kbnr/pppp1ppp/8/8/2P4q/P7/1P1PP1pP/RNBQKBNR\n"]},{"name":"stdout","output_type":"stream","text":["True r1bqk1nr/pppp1ppp/2n5/4p3/5P2/N5b1/PPPPP3/R1BQKBNR\n"]},{"name":"stdout","output_type":"stream","text":["True r1b1k2r/1pp2ppp/p1n2n2/8/P3p2P/2P3PB/4PP1N/2q1K2R\n"]},{"name":"stdout","output_type":"stream","text":["True rnb1k2r/ppp2ppp/3p1n2/5K2/1b1P4/6q1/PBP1P3/RN1Q1B2\n"]},{"name":"stdout","output_type":"stream","text":["True r1b1kb1r/pp2p1pp/8/3pn3/4n2P/1P3K2/P1PqPPP1/5B2\n"]},{"name":"stdout","output_type":"stream","text":["False rn5r/p2p1kp1/1p1B3p/2P1QP2/2B5/8/PPP1NPP1/RN2K2R\n","Self-play completed\n","Loaded existing validation data from validation_data.npy\n","\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 3.3696 - policy_output_accuracy: 0.1333 - value_output_mse: 6.3709e-04"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss improved from inf to 3.36960, saving model to kaggle/working/sigma_checkpoint.weights.h5\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 3.3696 - policy_output_accuracy: 0.1333 - value_output_mse: 6.3709e-04   \n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 3.4332 - policy_output_accuracy: 0.0333 - value_output_mse: 7.4389e-04"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss did not improve from 3.36960\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 3.4332 - policy_output_accuracy: 0.0333 - value_output_mse: 7.4389e-04\n"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 3.4881 - policy_output_accuracy: 0.0333 - value_output_mse: 7.5185e-04"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: loss did not improve from 3.36960\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 3.4881 - policy_output_accuracy: 0.0333 - value_output_mse: 7.5185e-04\n"]},{"name":"stdout","output_type":"stream","text":["Iteration 24/7000\n"]},{"name":"stdout","output_type":"stream","text":["False r3kbnr/p1pQ1ppp/4p3/1p2N3/4P3/2N5/PPP2PPP/R1B1KB1R\n"]}],"execution_count":null},{"id":"561522bf","cell_type":"markdown","source":"EARLY STOPİNG AND  ONCEDEN ELDE EDİLMİS AGIRLIKLAR ADD","metadata":{"id":"7fTFkjlIEHNH","papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"id":"c329b26c","cell_type":"code","source":"","metadata":{"id":"za1kYZLOlMC0","papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"execution_count":null}]}